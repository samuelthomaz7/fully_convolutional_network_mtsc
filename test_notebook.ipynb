{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-27 21:24:44.126883: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-27 21:24:44.543951: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-27 21:24:44.804182: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-27 21:24:44.943065: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-27 21:24:45.233347: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-27 21:24:46.619050: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722126289.309607 1005444 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722126290.032429 1005444 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722126290.032545 1005444 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from keras import layers, optimizers, losses, Model\n",
    "# from aeon import datasets\n",
    "import os\n",
    "# from tqdm import tqdm\n",
    "# import pickle\n",
    "from input.reading_datasets import get_all_datasets\n",
    "import seaborn as sns\n",
    "from preprocessing.get_dummies_labels import GetDummiesLabels\n",
    "from preprocessing.train_test_split_module import TrainTestSplit\n",
    "from models.multi_layer_perceptron import MultiLayerPerceprtron\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from path\n"
     ]
    }
   ],
   "source": [
    "uea_datasets = get_all_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722126290.204004 1005444 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722126290.204301 1005444 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722126290.204433 1005444 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722126291.535931 1005444 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722126291.536699 1005444 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-27 21:24:51.536740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1722126291.536997 1005444 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-27 21:24:51.538122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5578 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722126296.220561 1005599 service.cc:146] XLA service 0x7fcd70004910 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722126296.224797 1005599 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2024-07-27 21:24:56.500210: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-27 21:24:56.877704: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 7/15\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - f1_score: 0.1433 - loss: 2.9390 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722126300.423033 1005599 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.0000e+00 - f1_score: 0.3042 - loss: 2.3955"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-27 21:25:05.028025: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_56', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "2024-07-27 21:25:08.090060: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_56', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 650ms/step - accuracy: 0.0000e+00 - f1_score: 0.3183 - loss: 2.3505 - val_accuracy: 0.0000e+00 - val_f1_score: 0.8834 - val_loss: 0.2211 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - f1_score: 0.6533 - loss: 0.2332\n",
      "Epoch 2: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.6450e-05 - f1_score: 0.8884 - loss: 0.2604 - val_accuracy: 0.0000e+00 - val_f1_score: 0.9433 - val_loss: 0.1986 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 3.4901e-04 - f1_score: 0.9137 - loss: 0.1682 \n",
      "Epoch 3: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 3.5438e-04 - f1_score: 0.9163 - loss: 0.1679 - val_accuracy: 6.9565e-04 - val_f1_score: 0.9464 - val_loss: 0.1623 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0010 - f1_score: 0.9356 - loss: 0.1216  \n",
      "Epoch 4: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0011 - f1_score: 0.9424 - loss: 0.1194 - val_accuracy: 0.0017 - val_f1_score: 0.9534 - val_loss: 0.1086 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0027 - f1_score: 0.9650 - loss: 0.0524 \n",
      "Epoch 5: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0028 - f1_score: 0.9683 - loss: 0.0535 - val_accuracy: 0.0017 - val_f1_score: 0.9757 - val_loss: 0.0907 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0031 - f1_score: 0.9755 - loss: 0.0192 \n",
      "Epoch 6: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0032 - f1_score: 0.9764 - loss: 0.0201 - val_accuracy: 0.0024 - val_f1_score: 0.9835 - val_loss: 0.0937 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0062 - f1_score: 0.9649 - loss: 0.0263 \n",
      "Epoch 7: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0060 - f1_score: 0.9688 - loss: 0.0271 - val_accuracy: 0.0045 - val_f1_score: 0.9721 - val_loss: 0.1093 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0065 - f1_score: 0.9635 - loss: 0.0135 \n",
      "Epoch 8: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0059 - f1_score: 0.9775 - loss: 0.0142 - val_accuracy: 0.0066 - val_f1_score: 0.9823 - val_loss: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0062 - f1_score: 0.9576 - loss: 0.0101 \n",
      "Epoch 9: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0059 - f1_score: 0.9663 - loss: 0.0121 - val_accuracy: 0.0042 - val_f1_score: 0.9433 - val_loss: 0.2543 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0053 - f1_score: 0.9622 - loss: 0.0204 \n",
      "Epoch 10: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0050 - f1_score: 0.9770 - loss: 0.0169 - val_accuracy: 0.0073 - val_f1_score: 0.9823 - val_loss: 0.0663 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0079 - f1_score: 0.9779 - loss: 0.0119 \n",
      "Epoch 11: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0079 - f1_score: 0.9832 - loss: 0.0122 - val_accuracy: 0.0073 - val_f1_score: 0.9809 - val_loss: 0.0277 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0097 - f1_score: 0.9596 - loss: 0.0160 \n",
      "Epoch 12: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0092 - f1_score: 0.9735 - loss: 0.0247 - val_accuracy: 0.0066 - val_f1_score: 0.9739 - val_loss: 0.0801 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0084 - f1_score: 0.9642 - loss: 0.0258 \n",
      "Epoch 13: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0086 - f1_score: 0.9700 - loss: 0.0259 - val_accuracy: 0.0094 - val_f1_score: 0.9738 - val_loss: 0.2026 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0116 - f1_score: 0.9670 - loss: 0.0116 \n",
      "Epoch 14: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0114 - f1_score: 0.9719 - loss: 0.0116 - val_accuracy: 0.0097 - val_f1_score: 0.9677 - val_loss: 0.1736 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0137 - f1_score: 0.9709 - loss: 0.0021     \n",
      "Epoch 15: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0130 - f1_score: 0.9795 - loss: 0.0033 - val_accuracy: 0.0097 - val_f1_score: 0.9677 - val_loss: 0.1502 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0117 - f1_score: 0.9673 - loss: 0.0024 \n",
      "Epoch 16: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0118 - f1_score: 0.9775 - loss: 0.0026 - val_accuracy: 0.0115 - val_f1_score: 0.9672 - val_loss: 0.1409 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0122 - f1_score: 0.9480 - loss: 0.0021 \n",
      "Epoch 17: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0123 - f1_score: 0.9675 - loss: 0.0019 - val_accuracy: 0.0122 - val_f1_score: 0.9719 - val_loss: 0.1266 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0128 - f1_score: 0.9846 - loss: 9.3588e-04\n",
      "Epoch 18: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0130 - f1_score: 0.9875 - loss: 9.1750e-04 - val_accuracy: 0.0115 - val_f1_score: 0.9719 - val_loss: 0.1194 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0138 - f1_score: 0.9818 - loss: 9.0558e-04 \n",
      "Epoch 19: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0137 - f1_score: 0.9875 - loss: 0.0010 - val_accuracy: 0.0139 - val_f1_score: 0.9725 - val_loss: 0.1204 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0132 - f1_score: 0.9686 - loss: 5.4785e-04 \n",
      "Epoch 20: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0134 - f1_score: 0.9725 - loss: 5.4209e-04 - val_accuracy: 0.0150 - val_f1_score: 0.9725 - val_loss: 0.1236 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0153 - f1_score: 0.9833 - loss: 2.5020e-04 \n",
      "Epoch 21: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0156 - f1_score: 0.9875 - loss: 3.5654e-04 - val_accuracy: 0.0160 - val_f1_score: 0.9725 - val_loss: 0.1214 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0130 - f1_score: 0.9877 - loss: 3.8971e-04 \n",
      "Epoch 22: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0132 - f1_score: 0.9900 - loss: 5.5215e-04 - val_accuracy: 0.0177 - val_f1_score: 0.9725 - val_loss: 0.1080 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0158 - f1_score: 0.9754 - loss: 5.9439e-04 \n",
      "Epoch 23: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0159 - f1_score: 0.9800 - loss: 5.6668e-04 - val_accuracy: 0.0170 - val_f1_score: 0.9719 - val_loss: 0.1027 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0165 - f1_score: 0.9587 - loss: 0.0140 \n",
      "Epoch 24: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0164 - f1_score: 0.9624 - loss: 0.0167 - val_accuracy: 0.0143 - val_f1_score: 0.9719 - val_loss: 0.1518 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0134 - f1_score: 0.9745 - loss: 0.0152     \n",
      "Epoch 25: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0136 - f1_score: 0.9784 - loss: 0.0158 - val_accuracy: 0.0122 - val_f1_score: 0.9765 - val_loss: 0.2219 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0138 - f1_score: 0.9623 - loss: 0.0122 \n",
      "Epoch 26: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0133 - f1_score: 0.9694 - loss: 0.0381 - val_accuracy: 0.0139 - val_f1_score: 0.9286 - val_loss: 0.5601 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0131 - f1_score: 0.9016 - loss: 0.2771 \n",
      "Epoch 27: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0128 - f1_score: 0.9258 - loss: 0.2375 - val_accuracy: 0.0104 - val_f1_score: 0.9195 - val_loss: 0.4160 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0134 - f1_score: 0.9160 - loss: 0.1994 \n",
      "Epoch 28: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0132 - f1_score: 0.9348 - loss: 0.1845 - val_accuracy: 0.0153 - val_f1_score: 0.9586 - val_loss: 0.1915 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0161 - f1_score: 0.9384 - loss: 0.1700 \n",
      "Epoch 29: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0161 - f1_score: 0.9458 - loss: 0.1945 - val_accuracy: 0.0150 - val_f1_score: 0.9770 - val_loss: 0.0561 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0203 - f1_score: 0.9434 - loss: 0.1315\n",
      "Epoch 30: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0209 - f1_score: 0.9455 - loss: 0.1311 - val_accuracy: 0.0285 - val_f1_score: 0.8931 - val_loss: 0.7063 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0447 - f1_score: 0.9385 - loss: 0.0868 \n",
      "Epoch 31: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0432 - f1_score: 0.9508 - loss: 0.1064 - val_accuracy: 0.0310 - val_f1_score: 0.9126 - val_loss: 0.5147 - learning_rate: 0.0010\n",
      "Epoch 32/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0476 - f1_score: 0.9455 - loss: 0.1448    \n",
      "Epoch 32: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0473 - f1_score: 0.9467 - loss: 0.1457 - val_accuracy: 0.0337 - val_f1_score: 0.9647 - val_loss: 0.1861 - learning_rate: 0.0010\n",
      "Epoch 33/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0560 - f1_score: 0.9574 - loss: 0.0878 \n",
      "Epoch 33: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0550 - f1_score: 0.9594 - loss: 0.0964 - val_accuracy: 0.0383 - val_f1_score: 0.9460 - val_loss: 0.7185 - learning_rate: 0.0010\n",
      "Epoch 34/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0528 - f1_score: 0.9248 - loss: 0.1402 \n",
      "Epoch 34: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0539 - f1_score: 0.9425 - loss: 0.1524 - val_accuracy: 0.0456 - val_f1_score: 0.8866 - val_loss: 0.7413 - learning_rate: 0.0010\n",
      "Epoch 35/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1075 - f1_score: 0.7143 - loss: 0.1208\n",
      "Epoch 35: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0790 - f1_score: 0.9450 - loss: 0.0941 - val_accuracy: 0.0633 - val_f1_score: 0.9703 - val_loss: 0.0951 - learning_rate: 0.0010\n",
      "Epoch 36/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0610 - f1_score: 0.9425 - loss: 0.0222 \n",
      "Epoch 36: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0635 - f1_score: 0.9551 - loss: 0.0196 - val_accuracy: 0.0588 - val_f1_score: 0.9629 - val_loss: 0.2804 - learning_rate: 0.0010\n",
      "Epoch 37/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0774 - f1_score: 0.9546 - loss: 0.1811 \n",
      "Epoch 37: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0781 - f1_score: 0.9566 - loss: 0.1761 - val_accuracy: 0.0786 - val_f1_score: 0.9634 - val_loss: 0.2427 - learning_rate: 0.0010\n",
      "Epoch 38/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0950 - f1_score: 0.9723 - loss: 0.0196     \n",
      "Epoch 38: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0951 - f1_score: 0.9736 - loss: 0.0203 - val_accuracy: 0.0723 - val_f1_score: 0.9473 - val_loss: 0.2072 - learning_rate: 0.0010\n",
      "Epoch 39/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0941 - f1_score: 0.9369 - loss: 0.0697 \n",
      "Epoch 39: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0930 - f1_score: 0.9427 - loss: 0.0672 - val_accuracy: 0.0755 - val_f1_score: 0.9732 - val_loss: 0.2734 - learning_rate: 0.0010\n",
      "Epoch 40/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0977 - f1_score: 0.9699 - loss: 0.0033     \n",
      "Epoch 40: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0975 - f1_score: 0.9731 - loss: 0.0040 - val_accuracy: 0.0657 - val_f1_score: 0.9585 - val_loss: 0.2937 - learning_rate: 0.0010\n",
      "Epoch 41/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0362 - f1_score: 0.7200 - loss: 0.0026\n",
      "Epoch 41: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0860 - f1_score: 0.9780 - loss: 0.0083 - val_accuracy: 0.0668 - val_f1_score: 0.9672 - val_loss: 0.2863 - learning_rate: 0.0010\n",
      "Epoch 42/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1018 - f1_score: 0.9729 - loss: 0.0190 \n",
      "Epoch 42: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1020 - f1_score: 0.9756 - loss: 0.0180 - val_accuracy: 0.0734 - val_f1_score: 0.9672 - val_loss: 0.2644 - learning_rate: 0.0010\n",
      "Epoch 43/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1200 - f1_score: 0.8000 - loss: 2.1544e-04\n",
      "Epoch 43: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1161 - f1_score: 0.9856 - loss: 0.0324 - val_accuracy: 0.0765 - val_f1_score: 0.9585 - val_loss: 0.3623 - learning_rate: 0.0010\n",
      "Epoch 44/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0835 - f1_score: 0.9743 - loss: 0.0120     \n",
      "Epoch 44: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0865 - f1_score: 0.9783 - loss: 0.0113 - val_accuracy: 0.0765 - val_f1_score: 0.9775 - val_loss: 0.1611 - learning_rate: 0.0010\n",
      "Epoch 45/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1059 - f1_score: 0.9879 - loss: 0.0031      \n",
      "Epoch 45: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1055 - f1_score: 0.9894 - loss: 0.0066 - val_accuracy: 0.0720 - val_f1_score: 0.9775 - val_loss: 0.1265 - learning_rate: 0.0010\n",
      "Epoch 46/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1164 - f1_score: 0.9422 - loss: 3.1140e-04 \n",
      "Epoch 46: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1215 - f1_score: 0.9653 - loss: 0.0160 - val_accuracy: 0.0831 - val_f1_score: 0.9835 - val_loss: 0.1441 - learning_rate: 0.0010\n",
      "Epoch 47/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1299 - f1_score: 0.9734 - loss: 0.0063     \n",
      "Epoch 47: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1329 - f1_score: 0.9795 - loss: 0.0061 - val_accuracy: 0.0842 - val_f1_score: 0.9835 - val_loss: 0.1012 - learning_rate: 0.0010\n",
      "Epoch 48/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1245 - f1_score: 0.9617 - loss: 0.0053    \n",
      "Epoch 48: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1260 - f1_score: 0.9685 - loss: 0.0056 - val_accuracy: 0.0814 - val_f1_score: 0.9916 - val_loss: 0.0705 - learning_rate: 0.0010\n",
      "Epoch 49/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1413 - f1_score: 0.9498 - loss: 0.0266     \n",
      "Epoch 49: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1348 - f1_score: 0.9684 - loss: 0.0261 - val_accuracy: 0.0814 - val_f1_score: 0.9755 - val_loss: 0.1610 - learning_rate: 0.0010\n",
      "Epoch 50/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1330 - f1_score: 0.9736 - loss: 0.0056     \n",
      "Epoch 50: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1316 - f1_score: 0.9777 - loss: 0.0068 - val_accuracy: 0.0821 - val_f1_score: 0.9916 - val_loss: 0.0658 - learning_rate: 0.0010\n",
      "Epoch 51/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1272 - f1_score: 0.9767 - loss: 8.9944e-05 \n",
      "Epoch 51: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1272 - f1_score: 0.9825 - loss: 1.7991e-04 - val_accuracy: 0.0831 - val_f1_score: 0.9916 - val_loss: 0.0671 - learning_rate: 0.0010\n",
      "Epoch 52/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1231 - f1_score: 0.9673 - loss: 1.1015e-04 \n",
      "Epoch 52: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1263 - f1_score: 0.9775 - loss: 1.1795e-04 - val_accuracy: 0.0835 - val_f1_score: 0.9916 - val_loss: 0.0710 - learning_rate: 0.0010\n",
      "Epoch 53/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1365 - f1_score: 0.9733 - loss: 6.3892e-05 \n",
      "Epoch 53: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1363 - f1_score: 0.9750 - loss: 6.4389e-05 - val_accuracy: 0.0842 - val_f1_score: 0.9916 - val_loss: 0.0723 - learning_rate: 0.0010\n",
      "Epoch 54/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1389 - f1_score: 0.9491 - loss: 1.7664e-04 \n",
      "Epoch 54: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1370 - f1_score: 0.9650 - loss: 2.2106e-04 - val_accuracy: 0.0845 - val_f1_score: 0.9916 - val_loss: 0.0734 - learning_rate: 0.0010\n",
      "Epoch 55/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1211 - f1_score: 0.9867 - loss: 2.2163e-05 \n",
      "Epoch 55: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1222 - f1_score: 0.9900 - loss: 4.4951e-05 - val_accuracy: 0.0852 - val_f1_score: 0.9916 - val_loss: 0.0756 - learning_rate: 0.0010\n",
      "Epoch 56/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1234 - f1_score: 0.9692 - loss: 3.5465e-04 \n",
      "Epoch 56: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1242 - f1_score: 0.9750 - loss: 3.9727e-04 - val_accuracy: 0.0845 - val_f1_score: 0.9916 - val_loss: 0.0807 - learning_rate: 0.0010\n",
      "Epoch 57/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1370 - f1_score: 0.9520 - loss: 1.3199e-04 \n",
      "Epoch 57: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1325 - f1_score: 0.9700 - loss: 1.1116e-04 - val_accuracy: 0.0842 - val_f1_score: 0.9916 - val_loss: 0.0844 - learning_rate: 0.0010\n",
      "Epoch 58/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1410 - f1_score: 0.9818 - loss: 0.0020     \n",
      "Epoch 58: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1394 - f1_score: 0.9868 - loss: 0.0074 - val_accuracy: 0.0765 - val_f1_score: 0.9359 - val_loss: 0.2648 - learning_rate: 0.0010\n",
      "Epoch 59/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0988 - f1_score: 0.9645 - loss: 0.1387 \n",
      "Epoch 59: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1050 - f1_score: 0.9719 - loss: 0.1383 - val_accuracy: 0.0772 - val_f1_score: 0.9828 - val_loss: 0.0659 - learning_rate: 0.0010\n",
      "Epoch 60/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1162 - f1_score: 0.9568 - loss: 0.0648     \n",
      "Epoch 60: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1148 - f1_score: 0.9655 - loss: 0.0607 - val_accuracy: 0.0706 - val_f1_score: 0.9796 - val_loss: 0.0792 - learning_rate: 0.0010\n",
      "Epoch 61/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1050 - f1_score: 0.9752 - loss: 0.0093 \n",
      "Epoch 61: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1094 - f1_score: 0.9824 - loss: 0.0135 - val_accuracy: 0.0817 - val_f1_score: 0.9872 - val_loss: 0.0695 - learning_rate: 0.0010\n",
      "Epoch 62/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1129 - f1_score: 0.9656 - loss: 0.0117     \n",
      "Epoch 62: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1138 - f1_score: 0.9676 - loss: 0.0115 - val_accuracy: 0.0908 - val_f1_score: 0.9955 - val_loss: 0.0686 - learning_rate: 0.0010\n",
      "Epoch 63/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1451 - f1_score: 0.9600 - loss: 4.3170e-05 \n",
      "Epoch 63: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1408 - f1_score: 0.9719 - loss: 0.0022 - val_accuracy: 0.0883 - val_f1_score: 0.9955 - val_loss: 0.0602 - learning_rate: 0.0010\n",
      "Epoch 64/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1138 - f1_score: 0.7200 - loss: 0.0035\n",
      "Epoch 64: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1198 - f1_score: 0.9724 - loss: 0.0222 - val_accuracy: 0.0717 - val_f1_score: 0.9599 - val_loss: 0.2236 - learning_rate: 0.0010\n",
      "Epoch 65/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1023 - f1_score: 0.9671 - loss: 0.0868     \n",
      "Epoch 65: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1078 - f1_score: 0.9713 - loss: 0.0812 - val_accuracy: 0.0953 - val_f1_score: 0.9841 - val_loss: 0.2283 - learning_rate: 0.0010\n",
      "Epoch 66/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1557 - f1_score: 0.9609 - loss: 0.0415 \n",
      "Epoch 66: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1556 - f1_score: 0.9666 - loss: 0.0490 - val_accuracy: 0.1050 - val_f1_score: 0.9737 - val_loss: 0.2099 - learning_rate: 0.0010\n",
      "Epoch 67/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0637 - f1_score: 0.7200 - loss: 1.1655e-05\n",
      "Epoch 67: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1315 - f1_score: 0.9682 - loss: 0.0496 - val_accuracy: 0.1057 - val_f1_score: 0.9872 - val_loss: 0.0886 - learning_rate: 0.0010\n",
      "Epoch 68/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1238 - f1_score: 0.7600 - loss: 4.3980e-05\n",
      "Epoch 68: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1600 - f1_score: 0.9672 - loss: 0.1098 - val_accuracy: 0.1030 - val_f1_score: 0.9680 - val_loss: 0.2201 - learning_rate: 0.0010\n",
      "Epoch 69/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2300 - f1_score: 0.6800 - loss: 6.3330e-08\n",
      "Epoch 69: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1771 - f1_score: 0.9617 - loss: 0.0210 - val_accuracy: 0.1037 - val_f1_score: 0.9856 - val_loss: 0.1529 - learning_rate: 0.0010\n",
      "Epoch 70/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1579 - f1_score: 0.9729 - loss: 0.0061     \n",
      "Epoch 70: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1564 - f1_score: 0.9760 - loss: 0.0066 - val_accuracy: 0.1030 - val_f1_score: 0.9856 - val_loss: 0.2021 - learning_rate: 0.0010\n",
      "Epoch 71/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1754 - f1_score: 0.9681 - loss: 0.0027     \n",
      "Epoch 71: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1728 - f1_score: 0.9718 - loss: 0.0030 - val_accuracy: 0.1033 - val_f1_score: 0.9856 - val_loss: 0.2184 - learning_rate: 0.0010\n",
      "Epoch 72/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1593 - f1_score: 0.9556 - loss: 0.0391     \n",
      "Epoch 72: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1590 - f1_score: 0.9606 - loss: 0.0384 - val_accuracy: 0.1057 - val_f1_score: 0.9676 - val_loss: 0.2007 - learning_rate: 0.0010\n",
      "Epoch 73/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1300 - f1_score: 0.8000 - loss: 8.4564e-07\n",
      "Epoch 73: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1451 - f1_score: 0.9816 - loss: 0.0239 - val_accuracy: 0.1064 - val_f1_score: 0.9725 - val_loss: 0.4085 - learning_rate: 0.0010\n",
      "Epoch 74/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1616 - f1_score: 0.9486 - loss: 0.0295     \n",
      "Epoch 74: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1602 - f1_score: 0.9602 - loss: 0.0261 - val_accuracy: 0.0967 - val_f1_score: 0.9813 - val_loss: 0.1716 - learning_rate: 0.0010\n",
      "Epoch 75/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1344 - f1_score: 0.9636 - loss: 5.8237e-04 \n",
      "Epoch 75: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1369 - f1_score: 0.9750 - loss: 5.7819e-04 - val_accuracy: 0.0915 - val_f1_score: 0.9779 - val_loss: 0.2241 - learning_rate: 0.0010\n",
      "Epoch 76/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1462 - f1_score: 0.9654 - loss: 0.0021     \n",
      "Epoch 76: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1462 - f1_score: 0.9735 - loss: 0.0024 - val_accuracy: 0.1030 - val_f1_score: 0.9856 - val_loss: 0.0305 - learning_rate: 0.0010\n",
      "Epoch 77/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1037 - f1_score: 0.6400 - loss: 3.1292e-07\n",
      "Epoch 77: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1558 - f1_score: 0.9725 - loss: 1.4912e-04 - val_accuracy: 0.1179 - val_f1_score: 0.9859 - val_loss: 0.0274 - learning_rate: 0.0010\n",
      "Epoch 78/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1606 - f1_score: 0.9763 - loss: 0.0125     \n",
      "Epoch 78: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1601 - f1_score: 0.9803 - loss: 0.0126 - val_accuracy: 0.0922 - val_f1_score: 0.9919 - val_loss: 0.0392 - learning_rate: 0.0010\n",
      "Epoch 79/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1505 - f1_score: 0.9785 - loss: 1.4414e-04 \n",
      "Epoch 79: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1499 - f1_score: 0.9825 - loss: 1.7002e-04 - val_accuracy: 0.0887 - val_f1_score: 0.9705 - val_loss: 0.0817 - learning_rate: 0.0010\n",
      "Epoch 80/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1086 - f1_score: 0.9560 - loss: 6.5505e-06 \n",
      "Epoch 80: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1180 - f1_score: 0.9725 - loss: 2.6749e-05 - val_accuracy: 0.0883 - val_f1_score: 0.9705 - val_loss: 0.0885 - learning_rate: 0.0010\n",
      "Epoch 81/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1327 - f1_score: 0.9840 - loss: 1.1160e-04 \n",
      "Epoch 81: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1330 - f1_score: 0.9850 - loss: 1.1160e-04 - val_accuracy: 0.0890 - val_f1_score: 0.9782 - val_loss: 0.0580 - learning_rate: 0.0010\n",
      "Epoch 82/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1250 - f1_score: 0.9600 - loss: 2.2710e-06 \n",
      "Epoch 82: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1262 - f1_score: 0.9725 - loss: 2.6351e-06 - val_accuracy: 0.0890 - val_f1_score: 0.9782 - val_loss: 0.0555 - learning_rate: 0.0010\n",
      "Epoch 83/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1438 - f1_score: 0.9737 - loss: 0.0034     \n",
      "Epoch 83: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1431 - f1_score: 0.9782 - loss: 0.0035 - val_accuracy: 0.0915 - val_f1_score: 0.9919 - val_loss: 0.0430 - learning_rate: 0.0010\n",
      "Epoch 84/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1409 - f1_score: 0.9552 - loss: 0.0041     \n",
      "Epoch 84: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1420 - f1_score: 0.9678 - loss: 0.0084 - val_accuracy: 0.0950 - val_f1_score: 0.9816 - val_loss: 0.0374 - learning_rate: 0.0010\n",
      "Epoch 85/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1697 - f1_score: 0.9575 - loss: 0.0290     \n",
      "Epoch 85: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1687 - f1_score: 0.9671 - loss: 0.0349 - val_accuracy: 0.0904 - val_f1_score: 0.9535 - val_loss: 0.5369 - learning_rate: 0.0010\n",
      "Epoch 86/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1461 - f1_score: 0.9605 - loss: 0.0798     \n",
      "Epoch 86: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1475 - f1_score: 0.9677 - loss: 0.0863 - val_accuracy: 0.0883 - val_f1_score: 0.9896 - val_loss: 0.0731 - learning_rate: 0.0010\n",
      "Epoch 87/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1451 - f1_score: 0.9479 - loss: 0.0558     \n",
      "Epoch 87: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1454 - f1_score: 0.9629 - loss: 0.0693 - val_accuracy: 0.0880 - val_f1_score: 0.9673 - val_loss: 0.2777 - learning_rate: 0.0010\n",
      "Epoch 88/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1767 - f1_score: 0.9560 - loss: 0.1515     \n",
      "Epoch 88: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1701 - f1_score: 0.9685 - loss: 0.1509 - val_accuracy: 0.0797 - val_f1_score: 0.9644 - val_loss: 0.5147 - learning_rate: 0.0010\n",
      "Epoch 89/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1414 - f1_score: 0.9487 - loss: 0.0491     \n",
      "Epoch 89: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1434 - f1_score: 0.9570 - loss: 0.0456 - val_accuracy: 0.0929 - val_f1_score: 0.9776 - val_loss: 0.1988 - learning_rate: 0.0010\n",
      "Epoch 90/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1636 - f1_score: 0.9549 - loss: 0.0486     \n",
      "Epoch 90: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1641 - f1_score: 0.9608 - loss: 0.0683 - val_accuracy: 0.1242 - val_f1_score: 0.9816 - val_loss: 0.0706 - learning_rate: 0.0010\n",
      "Epoch 91/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1874 - f1_score: 0.9501 - loss: 0.0492     \n",
      "Epoch 91: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1881 - f1_score: 0.9545 - loss: 0.0553 - val_accuracy: 0.1530 - val_f1_score: 0.9707 - val_loss: 0.3235 - learning_rate: 0.0010\n",
      "Epoch 92/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2330 - f1_score: 0.9414 - loss: 0.0210     \n",
      "Epoch 92: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2312 - f1_score: 0.9563 - loss: 0.0291 - val_accuracy: 0.1784 - val_f1_score: 0.9676 - val_loss: 0.1088 - learning_rate: 0.0010\n",
      "Epoch 93/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2482 - f1_score: 0.9753 - loss: 0.1126 \n",
      "Epoch 93: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2494 - f1_score: 0.9817 - loss: 0.1260 - val_accuracy: 0.1823 - val_f1_score: 0.9536 - val_loss: 0.3998 - learning_rate: 0.0010\n",
      "Epoch 94/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2857 - f1_score: 0.9517 - loss: 0.0729     \n",
      "Epoch 94: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2843 - f1_score: 0.9568 - loss: 0.0992 - val_accuracy: 0.2038 - val_f1_score: 0.9601 - val_loss: 0.3898 - learning_rate: 0.0010\n",
      "Epoch 95/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3027 - f1_score: 0.9308 - loss: 0.0635     \n",
      "Epoch 95: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2913 - f1_score: 0.9597 - loss: 0.0656 - val_accuracy: 0.2073 - val_f1_score: 0.9474 - val_loss: 0.5563 - learning_rate: 0.0010\n",
      "Epoch 96/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2758 - f1_score: 0.9530 - loss: 0.0733     \n",
      "Epoch 96: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2755 - f1_score: 0.9655 - loss: 0.0644 - val_accuracy: 0.2560 - val_f1_score: 0.9863 - val_loss: 0.0295 - learning_rate: 0.0010\n",
      "Epoch 97/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2763 - f1_score: 0.9727 - loss: 0.0095     \n",
      "Epoch 97: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2792 - f1_score: 0.9752 - loss: 0.0103 - val_accuracy: 0.2664 - val_f1_score: 0.9782 - val_loss: 0.3088 - learning_rate: 0.0010\n",
      "Epoch 98/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2783 - f1_score: 0.9564 - loss: 8.6067e-04 \n",
      "Epoch 98: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2826 - f1_score: 0.9700 - loss: 0.0010 - val_accuracy: 0.2508 - val_f1_score: 0.9782 - val_loss: 0.2827 - learning_rate: 0.0010\n",
      "Epoch 99/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3122 - f1_score: 0.9680 - loss: 0.0051     \n",
      "Epoch 99: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3095 - f1_score: 0.9800 - loss: 0.0041 - val_accuracy: 0.2511 - val_f1_score: 1.0000 - val_loss: 0.0044 - learning_rate: 0.0010\n",
      "Epoch 100/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2731 - f1_score: 0.9619 - loss: 0.0264     \n",
      "Epoch 100: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2857 - f1_score: 0.9753 - loss: 0.0293 - val_accuracy: 0.2504 - val_f1_score: 0.9725 - val_loss: 0.6631 - learning_rate: 0.0010\n",
      "Epoch 101/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3210 - f1_score: 0.9552 - loss: 0.0594 \n",
      "Epoch 101: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3164 - f1_score: 0.9640 - loss: 0.0665 - val_accuracy: 0.2574 - val_f1_score: 0.9396 - val_loss: 0.3649 - learning_rate: 0.0010\n",
      "Epoch 102/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3310 - f1_score: 0.9605 - loss: 0.0191     \n",
      "Epoch 102: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3290 - f1_score: 0.9695 - loss: 0.0293 - val_accuracy: 0.2588 - val_f1_score: 0.9293 - val_loss: 0.2163 - learning_rate: 0.0010\n",
      "Epoch 103/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3612 - f1_score: 0.7200 - loss: 0.0000e+00\n",
      "Epoch 103: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3481 - f1_score: 0.9709 - loss: 0.0648 - val_accuracy: 0.2765 - val_f1_score: 0.9809 - val_loss: 0.0558 - learning_rate: 0.0010\n",
      "Epoch 104/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3231 - f1_score: 0.9668 - loss: 0.1026 \n",
      "Epoch 104: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3248 - f1_score: 0.9680 - loss: 0.1043 - val_accuracy: 0.3078 - val_f1_score: 0.9896 - val_loss: 0.1768 - learning_rate: 0.0010\n",
      "Epoch 105/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4046 - f1_score: 0.9732 - loss: 0.0114     \n",
      "Epoch 105: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4028 - f1_score: 0.9778 - loss: 0.0120 - val_accuracy: 0.3402 - val_f1_score: 0.9636 - val_loss: 0.5900 - learning_rate: 0.0010\n",
      "Epoch 106/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3774 - f1_score: 0.9728 - loss: 0.0307     \n",
      "Epoch 106: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3784 - f1_score: 0.9771 - loss: 0.0308 - val_accuracy: 0.3266 - val_f1_score: 0.9732 - val_loss: 0.8788 - learning_rate: 0.0010\n",
      "Epoch 107/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3747 - f1_score: 0.9504 - loss: 0.2463     \n",
      "Epoch 107: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3763 - f1_score: 0.9559 - loss: 0.2843 - val_accuracy: 0.3203 - val_f1_score: 0.9543 - val_loss: 0.6251 - learning_rate: 0.0010\n",
      "Epoch 108/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3973 - f1_score: 0.9514 - loss: 0.1832     \n",
      "Epoch 108: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3937 - f1_score: 0.9573 - loss: 0.1786 - val_accuracy: 0.3043 - val_f1_score: 0.9209 - val_loss: 1.0596 - learning_rate: 0.0010\n",
      "Epoch 109/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3790 - f1_score: 0.9560 - loss: 0.6172 \n",
      "Epoch 109: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3861 - f1_score: 0.9637 - loss: 0.5854 - val_accuracy: 0.3395 - val_f1_score: 0.9507 - val_loss: 0.8463 - learning_rate: 0.0010\n",
      "Epoch 110/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4062 - f1_score: 0.9548 - loss: 0.3635  \n",
      "Epoch 110: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4108 - f1_score: 0.9585 - loss: 0.3595 - val_accuracy: 0.4184 - val_f1_score: 0.9851 - val_loss: 0.5188 - learning_rate: 0.0010\n",
      "Epoch 111/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4843 - f1_score: 0.9589 - loss: 0.0445 \n",
      "Epoch 111: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4837 - f1_score: 0.9641 - loss: 0.0591 - val_accuracy: 0.3948 - val_f1_score: 0.9916 - val_loss: 0.4243 - learning_rate: 0.0010\n",
      "Epoch 112/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4713 - f1_score: 0.9619 - loss: 0.2741 \n",
      "Epoch 112: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4757 - f1_score: 0.9678 - loss: 0.2448 - val_accuracy: 0.3767 - val_f1_score: 0.9813 - val_loss: 0.4520 - learning_rate: 0.0010\n",
      "Epoch 113/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4949 - f1_score: 0.9677 - loss: 0.0085     \n",
      "Epoch 113: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4969 - f1_score: 0.9757 - loss: 0.0121 - val_accuracy: 0.4090 - val_f1_score: 0.9586 - val_loss: 0.9007 - learning_rate: 0.0010\n",
      "Epoch 114/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4973 - f1_score: 0.9597 - loss: 0.1219     \n",
      "Epoch 114: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5036 - f1_score: 0.9643 - loss: 0.1328 - val_accuracy: 0.4393 - val_f1_score: 0.9592 - val_loss: 0.8234 - learning_rate: 0.0010\n",
      "Epoch 115/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - f1_score: 0.9796 - loss: 0.0147    \n",
      "Epoch 115: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5325 - f1_score: 0.9807 - loss: 0.0151 - val_accuracy: 0.4473 - val_f1_score: 0.9560 - val_loss: 0.9108 - learning_rate: 0.0010\n",
      "Epoch 116/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5239 - f1_score: 0.9508 - loss: 0.1372 \n",
      "Epoch 116: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5271 - f1_score: 0.9620 - loss: 0.1140 - val_accuracy: 0.4202 - val_f1_score: 0.9617 - val_loss: 1.0137 - learning_rate: 0.0010\n",
      "Epoch 117/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5466 - f1_score: 0.9503 - loss: 0.1776     \n",
      "Epoch 117: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5491 - f1_score: 0.9660 - loss: 0.1471 - val_accuracy: 0.5061 - val_f1_score: 0.9535 - val_loss: 1.7128 - learning_rate: 0.0010\n",
      "Epoch 118/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5107 - f1_score: 0.9513 - loss: 0.0451     \n",
      "Epoch 118: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5369 - f1_score: 0.9722 - loss: 0.0545 - val_accuracy: 0.4873 - val_f1_score: 0.9617 - val_loss: 1.2855 - learning_rate: 0.0010\n",
      "Epoch 119/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6440 - f1_score: 0.9695 - loss: 0.0197     \n",
      "Epoch 119: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6324 - f1_score: 0.9760 - loss: 0.0196 - val_accuracy: 0.4508 - val_f1_score: 0.9528 - val_loss: 1.2720 - learning_rate: 0.0010\n",
      "Epoch 120/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6034 - f1_score: 0.9716 - loss: 0.0538     \n",
      "Epoch 120: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6046 - f1_score: 0.9767 - loss: 0.0627 - val_accuracy: 0.4212 - val_f1_score: 0.9484 - val_loss: 1.3843 - learning_rate: 0.0010\n",
      "Epoch 121/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6122 - f1_score: 0.9660 - loss: 0.1605\n",
      "Epoch 121: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6101 - f1_score: 0.9677 - loss: 0.1551 - val_accuracy: 0.4122 - val_f1_score: 0.9298 - val_loss: 1.8908 - learning_rate: 0.0010\n",
      "Epoch 122/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6055 - f1_score: 0.9773 - loss: 0.0174    \n",
      "Epoch 122: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6050 - f1_score: 0.9796 - loss: 0.0190 - val_accuracy: 0.4136 - val_f1_score: 0.9484 - val_loss: 1.4763 - learning_rate: 0.0010\n",
      "Epoch 123/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5476 - f1_score: 0.9709 - loss: 0.0267\n",
      "Epoch 123: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5491 - f1_score: 0.9725 - loss: 0.0284 - val_accuracy: 0.4470 - val_f1_score: 0.9484 - val_loss: 1.3786 - learning_rate: 0.0010\n",
      "Epoch 124/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6029 - f1_score: 0.9854 - loss: 3.5977e-04\n",
      "Epoch 124: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6009 - f1_score: 0.9870 - loss: 6.0796e-04 - val_accuracy: 0.4483 - val_f1_score: 0.9484 - val_loss: 1.3114 - learning_rate: 0.0010\n",
      "Epoch 125/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5985 - f1_score: 0.9499 - loss: 0.0139     \n",
      "Epoch 125: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5946 - f1_score: 0.9659 - loss: 0.0268 - val_accuracy: 0.4358 - val_f1_score: 0.9484 - val_loss: 1.3002 - learning_rate: 0.0010\n",
      "Epoch 126/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6046 - f1_score: 0.9730 - loss: 0.0098    \n",
      "Epoch 126: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6044 - f1_score: 0.9761 - loss: 0.0104 - val_accuracy: 0.4717 - val_f1_score: 0.9484 - val_loss: 1.2287 - learning_rate: 0.0010\n",
      "Epoch 127/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6319 - f1_score: 0.9709 - loss: 5.3406e-05 \n",
      "Epoch 127: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6236 - f1_score: 0.9800 - loss: 6.1823e-05 - val_accuracy: 0.4730 - val_f1_score: 0.9484 - val_loss: 1.1840 - learning_rate: 0.0010\n",
      "Epoch 128/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5927 - f1_score: 0.9856 - loss: 0.0022    \n",
      "Epoch 128: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5962 - f1_score: 0.9871 - loss: 0.0055 - val_accuracy: 0.4783 - val_f1_score: 0.9484 - val_loss: 1.1663 - learning_rate: 0.0010\n",
      "Epoch 129/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6498 - f1_score: 0.9725 - loss: 0.0139     \n",
      "Epoch 129: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6386 - f1_score: 0.9819 - loss: 0.0134 - val_accuracy: 0.4797 - val_f1_score: 0.9475 - val_loss: 1.4284 - learning_rate: 0.0010\n",
      "Epoch 130/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6153 - f1_score: 0.9679 - loss: 0.0223     \n",
      "Epoch 130: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6160 - f1_score: 0.9745 - loss: 0.0418 - val_accuracy: 0.5005 - val_f1_score: 0.9621 - val_loss: 1.3158 - learning_rate: 0.0010\n",
      "Epoch 131/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6254 - f1_score: 0.9748 - loss: 0.0032     \n",
      "Epoch 131: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6351 - f1_score: 0.9832 - loss: 0.0047 - val_accuracy: 0.5071 - val_f1_score: 0.9621 - val_loss: 1.2090 - learning_rate: 0.0010\n",
      "Epoch 132/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6698 - f1_score: 0.9533 - loss: 5.6464e-06 \n",
      "Epoch 132: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6688 - f1_score: 0.9650 - loss: 6.6521e-06 - val_accuracy: 0.5183 - val_f1_score: 0.9621 - val_loss: 1.1705 - learning_rate: 0.0010\n",
      "Epoch 133/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6251 - f1_score: 0.9707 - loss: 0.0035 \n",
      "Epoch 133: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6275 - f1_score: 0.9725 - loss: 0.0033 - val_accuracy: 0.5290 - val_f1_score: 0.9621 - val_loss: 1.1535 - learning_rate: 0.0010\n",
      "Epoch 134/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6839 - f1_score: 0.9688 - loss: 0.0251     \n",
      "Epoch 134: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6771 - f1_score: 0.9778 - loss: 0.0259 - val_accuracy: 0.5353 - val_f1_score: 0.9595 - val_loss: 1.4737 - learning_rate: 0.0010\n",
      "Epoch 135/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6879 - f1_score: 0.9771 - loss: 3.7692e-07 \n",
      "Epoch 135: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6846 - f1_score: 0.9800 - loss: 3.7292e-07 - val_accuracy: 0.5391 - val_f1_score: 0.9495 - val_loss: 1.8038 - learning_rate: 0.0010\n",
      "Epoch 136/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6459 - f1_score: 0.9884 - loss: 0.0027     \n",
      "Epoch 136: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6467 - f1_score: 0.9888 - loss: 0.0033 - val_accuracy: 0.5409 - val_f1_score: 0.9484 - val_loss: 1.4845 - learning_rate: 0.0010\n",
      "Epoch 137/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6740 - f1_score: 0.9682 - loss: 0.0086 \n",
      "Epoch 137: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6747 - f1_score: 0.9701 - loss: 0.0083 - val_accuracy: 0.5621 - val_f1_score: 0.9532 - val_loss: 1.0947 - learning_rate: 0.0010\n",
      "Epoch 138/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7027 - f1_score: 0.9733 - loss: 3.8005e-07 \n",
      "Epoch 138: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6962 - f1_score: 0.9846 - loss: 0.0018 - val_accuracy: 0.5652 - val_f1_score: 0.9532 - val_loss: 1.1587 - learning_rate: 0.0010\n",
      "Epoch 139/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6834 - f1_score: 0.9606 - loss: 0.0214     \n",
      "Epoch 139: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6842 - f1_score: 0.9630 - loss: 0.0207 - val_accuracy: 0.6003 - val_f1_score: 0.9621 - val_loss: 1.2323 - learning_rate: 0.0010\n",
      "Epoch 140/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7438 - f1_score: 0.6800 - loss: 0.0000e+00\n",
      "Epoch 140: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7068 - f1_score: 0.9800 - loss: 2.7914e-08 - val_accuracy: 0.5997 - val_f1_score: 0.9621 - val_loss: 1.2596 - learning_rate: 0.0010\n",
      "Epoch 141/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7325 - f1_score: 0.6800 - loss: 0.0000e+00\n",
      "Epoch 141: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6888 - f1_score: 0.9677 - loss: 0.0224 - val_accuracy: 0.5906 - val_f1_score: 0.9621 - val_loss: 1.2294 - learning_rate: 0.0010\n",
      "Epoch 142/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6821 - f1_score: 0.9828 - loss: 0.0295     \n",
      "Epoch 142: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6839 - f1_score: 0.9838 - loss: 0.0302 - val_accuracy: 0.6003 - val_f1_score: 0.9621 - val_loss: 1.2185 - learning_rate: 0.0010\n",
      "Epoch 143/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7348 - f1_score: 0.9422 - loss: 1.4736e-05 \n",
      "Epoch 143: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7363 - f1_score: 0.9675 - loss: 1.3108e-05 - val_accuracy: 0.5972 - val_f1_score: 0.9484 - val_loss: 1.5364 - learning_rate: 0.0010\n",
      "Epoch 144/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6939 - f1_score: 0.9656 - loss: 0.0061     \n",
      "Epoch 144: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6989 - f1_score: 0.9717 - loss: 0.0092 - val_accuracy: 0.6021 - val_f1_score: 0.9621 - val_loss: 1.2106 - learning_rate: 0.0010\n",
      "Epoch 145/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7256 - f1_score: 0.9787 - loss: 3.2386e-08 \n",
      "Epoch 145: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7257 - f1_score: 0.9800 - loss: 3.1884e-08 - val_accuracy: 0.6028 - val_f1_score: 0.9732 - val_loss: 1.2183 - learning_rate: 0.0010\n",
      "Epoch 146/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6925 - f1_score: 0.8800 - loss: 0.0000e+00\n",
      "Epoch 146: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7242 - f1_score: 0.9900 - loss: 6.8381e-05 - val_accuracy: 0.6031 - val_f1_score: 0.9732 - val_loss: 1.2306 - learning_rate: 0.0010\n",
      "Epoch 147/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7494 - f1_score: 0.9760 - loss: 3.6950e-10 \n",
      "Epoch 147: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7485 - f1_score: 0.9775 - loss: 3.6260e-10 - val_accuracy: 0.6031 - val_f1_score: 0.9732 - val_loss: 1.2337 - learning_rate: 0.0010\n",
      "Epoch 148/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7675 - f1_score: 0.8000 - loss: 0.0000e+00\n",
      "Epoch 148: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7459 - f1_score: 0.9850 - loss: 6.0792e-09 - val_accuracy: 0.6031 - val_f1_score: 0.9732 - val_loss: 1.2345 - learning_rate: 0.0010\n",
      "Epoch 149/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7201 - f1_score: 0.9733 - loss: 2.7992e-07 \n",
      "Epoch 149: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7195 - f1_score: 0.9750 - loss: 3.3658e-07 - val_accuracy: 0.6031 - val_f1_score: 0.9732 - val_loss: 1.2346 - learning_rate: 0.0010\n",
      "Epoch 150/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7837 - f1_score: 0.7600 - loss: 0.0000e+00\n",
      "Epoch 150: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7138 - f1_score: 0.9800 - loss: 1.4962e-08 - val_accuracy: 0.6031 - val_f1_score: 0.9732 - val_loss: 1.2347 - learning_rate: 0.0010\n",
      "Epoch 151/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7130 - f1_score: 0.9600 - loss: 5.2502e-08 \n",
      "Epoch 151: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7135 - f1_score: 0.9725 - loss: 4.4901e-08 - val_accuracy: 0.6031 - val_f1_score: 0.9732 - val_loss: 1.2347 - learning_rate: 0.0010\n",
      "Epoch 152/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7070 - f1_score: 0.9760 - loss: 0.0000e+00 \n",
      "Epoch 152: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7075 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.6031 - val_f1_score: 0.9732 - val_loss: 1.2347 - learning_rate: 0.0010\n",
      "Epoch 153/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7455 - f1_score: 0.9733 - loss: 4.7036e-06 \n",
      "Epoch 153: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7443 - f1_score: 0.9750 - loss: 5.1882e-06 - val_accuracy: 0.6028 - val_f1_score: 0.9732 - val_loss: 1.2347 - learning_rate: 0.0010\n",
      "Epoch 154/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6858 - f1_score: 0.9787 - loss: 2.3798e-08 \n",
      "Epoch 154: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6872 - f1_score: 0.9800 - loss: 2.4092e-08 - val_accuracy: 0.6024 - val_f1_score: 0.9732 - val_loss: 1.2346 - learning_rate: 0.0010\n",
      "Epoch 155/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7131 - f1_score: 0.9815 - loss: 2.0559e-09 \n",
      "Epoch 155: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7158 - f1_score: 0.9850 - loss: 2.0626e-09 - val_accuracy: 0.6024 - val_f1_score: 0.9732 - val_loss: 1.2348 - learning_rate: 0.0010\n",
      "Epoch 156/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7369 - f1_score: 0.9743 - loss: 7.8950e-11 \n",
      "Epoch 156: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7362 - f1_score: 0.9775 - loss: 1.3387e-10 - val_accuracy: 0.6024 - val_f1_score: 0.9732 - val_loss: 1.2347 - learning_rate: 0.0010\n",
      "Epoch 157/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7468 - f1_score: 0.9634 - loss: 0.0088     \n",
      "Epoch 157: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7461 - f1_score: 0.9656 - loss: 0.0085 - val_accuracy: 0.6550 - val_f1_score: 0.9684 - val_loss: 1.4476 - learning_rate: 0.0010\n",
      "Epoch 158/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7166 - f1_score: 0.9780 - loss: 0.0051     \n",
      "Epoch 158: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7176 - f1_score: 0.9791 - loss: 0.0051 - val_accuracy: 0.6699 - val_f1_score: 0.9547 - val_loss: 1.5594 - learning_rate: 0.0010\n",
      "Epoch 159/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7618 - f1_score: 0.9556 - loss: 0.0000e+00 \n",
      "Epoch 159: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7549 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.6685 - val_f1_score: 0.9321 - val_loss: 3.2163 - learning_rate: 0.0010\n",
      "Epoch 160/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7503 - f1_score: 0.9588 - loss: 0.0127     \n",
      "Epoch 160: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7519 - f1_score: 0.9746 - loss: 0.0349 - val_accuracy: 0.6602 - val_f1_score: 0.9608 - val_loss: 2.2912 - learning_rate: 0.0010\n",
      "Epoch 161/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7828 - f1_score: 0.9833 - loss: 1.3380e-07\n",
      "Epoch 161: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7795 - f1_score: 0.9875 - loss: 1.2478e-07 - val_accuracy: 0.6275 - val_f1_score: 0.9308 - val_loss: 3.5592 - learning_rate: 0.0010\n",
      "Epoch 162/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7028 - f1_score: 0.9584 - loss: 0.1312 \n",
      "Epoch 162: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7174 - f1_score: 0.9764 - loss: 0.1251 - val_accuracy: 0.6271 - val_f1_score: 0.9684 - val_loss: 1.2404 - learning_rate: 0.0010\n",
      "Epoch 163/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7352 - f1_score: 0.9689 - loss: 5.5718e-07 \n",
      "Epoch 163: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7323 - f1_score: 0.9825 - loss: 6.7270e-07 - val_accuracy: 0.6243 - val_f1_score: 0.9609 - val_loss: 1.4401 - learning_rate: 0.0010\n",
      "Epoch 164/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6937 - f1_score: 0.9700 - loss: 1.7299e-06\n",
      "Epoch 164: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6943 - f1_score: 0.9775 - loss: 7.5378e-05 - val_accuracy: 0.6285 - val_f1_score: 0.9609 - val_loss: 1.4703 - learning_rate: 0.0010\n",
      "Epoch 165/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7066 - f1_score: 0.9800 - loss: 8.9317e-08 \n",
      "Epoch 165: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7099 - f1_score: 0.9875 - loss: 8.7453e-08 - val_accuracy: 0.6282 - val_f1_score: 0.9609 - val_loss: 1.4169 - learning_rate: 0.0010\n",
      "Epoch 166/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7187 - f1_score: 0.9745 - loss: 0.1461     \n",
      "Epoch 166: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7213 - f1_score: 0.9789 - loss: 0.1302 - val_accuracy: 0.6278 - val_f1_score: 0.9574 - val_loss: 1.4730 - learning_rate: 0.0010\n",
      "Epoch 167/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7196 - f1_score: 0.9459 - loss: 0.0039     \n",
      "Epoch 167: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7167 - f1_score: 0.9634 - loss: 0.0160 - val_accuracy: 0.6226 - val_f1_score: 0.9635 - val_loss: 1.2529 - learning_rate: 0.0010\n",
      "Epoch 168/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7559 - f1_score: 0.9711 - loss: 0.0502     \n",
      "Epoch 168: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7545 - f1_score: 0.9784 - loss: 0.0481 - val_accuracy: 0.6261 - val_f1_score: 0.9621 - val_loss: 1.2659 - learning_rate: 0.0010\n",
      "Epoch 169/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7030 - f1_score: 0.9693 - loss: 0.0065     \n",
      "Epoch 169: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7092 - f1_score: 0.9764 - loss: 0.0099 - val_accuracy: 0.6167 - val_f1_score: 0.9561 - val_loss: 1.3522 - learning_rate: 0.0010\n",
      "Epoch 170/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7754 - f1_score: 0.9600 - loss: 2.5806e-06 \n",
      "Epoch 170: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7725 - f1_score: 0.9750 - loss: 2.3854e-06 - val_accuracy: 0.6080 - val_f1_score: 0.9561 - val_loss: 1.3946 - learning_rate: 0.0010\n",
      "Epoch 171/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7356 - f1_score: 0.9673 - loss: 1.0871e-04 \n",
      "Epoch 171: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7348 - f1_score: 0.9775 - loss: 9.6005e-05 - val_accuracy: 0.6090 - val_f1_score: 0.9561 - val_loss: 1.4018 - learning_rate: 0.0010\n",
      "Epoch 172/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7263 - f1_score: 0.9794 - loss: 0.0019     \n",
      "Epoch 172: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7296 - f1_score: 0.9863 - loss: 0.0039 - val_accuracy: 0.6160 - val_f1_score: 0.9561 - val_loss: 1.4205 - learning_rate: 0.0010\n",
      "Epoch 173/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8018 - f1_score: 0.9516 - loss: 0.0429     \n",
      "Epoch 173: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7905 - f1_score: 0.9689 - loss: 0.0381 - val_accuracy: 0.6111 - val_f1_score: 0.9348 - val_loss: 1.8412 - learning_rate: 0.0010\n",
      "Epoch 174/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7548 - f1_score: 0.9507 - loss: 0.0973     \n",
      "Epoch 174: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7544 - f1_score: 0.9673 - loss: 0.0840 - val_accuracy: 0.6438 - val_f1_score: 0.9574 - val_loss: 1.5047 - learning_rate: 0.0010\n",
      "Epoch 175/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7574 - f1_score: 0.9788 - loss: 0.1690\n",
      "Epoch 175: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7555 - f1_score: 0.9830 - loss: 0.1396 - val_accuracy: 0.6212 - val_f1_score: 0.9574 - val_loss: 1.6625 - learning_rate: 0.0010\n",
      "Epoch 176/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7545 - f1_score: 0.9723 - loss: 0.0334\n",
      "Epoch 176: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7545 - f1_score: 0.9737 - loss: 0.0352 - val_accuracy: 0.5892 - val_f1_score: 0.9574 - val_loss: 1.8247 - learning_rate: 0.0010\n",
      "Epoch 177/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7203 - f1_score: 0.9667 - loss: 0.0027    \n",
      "Epoch 177: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7194 - f1_score: 0.9702 - loss: 0.0036 - val_accuracy: 0.5732 - val_f1_score: 0.9574 - val_loss: 1.7497 - learning_rate: 0.0010\n",
      "Epoch 178/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7116 - f1_score: 0.9637 - loss: 0.0051     \n",
      "Epoch 178: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7199 - f1_score: 0.9758 - loss: 0.0178 - val_accuracy: 0.6094 - val_f1_score: 0.9621 - val_loss: 1.5836 - learning_rate: 0.0010\n",
      "Epoch 179/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7410 - f1_score: 0.9721 - loss: 0.0185     \n",
      "Epoch 179: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7394 - f1_score: 0.9757 - loss: 0.0343 - val_accuracy: 0.6532 - val_f1_score: 0.9702 - val_loss: 1.2791 - learning_rate: 0.0010\n",
      "Epoch 180/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7469 - f1_score: 0.9640 - loss: 2.2075e-05 \n",
      "Epoch 180: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7492 - f1_score: 0.9775 - loss: 1.8259e-05 - val_accuracy: 0.6560 - val_f1_score: 0.9702 - val_loss: 1.1202 - learning_rate: 0.0010\n",
      "Epoch 181/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7493 - f1_score: 0.9754 - loss: 2.4125e-06 \n",
      "Epoch 181: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7507 - f1_score: 0.9800 - loss: 2.4105e-06 - val_accuracy: 0.6539 - val_f1_score: 0.9702 - val_loss: 1.0996 - learning_rate: 0.0010\n",
      "Epoch 182/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7503 - f1_score: 0.9769 - loss: 0.0037     \n",
      "Epoch 182: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7514 - f1_score: 0.9808 - loss: 0.0036 - val_accuracy: 0.6414 - val_f1_score: 0.9702 - val_loss: 1.0826 - learning_rate: 0.0010\n",
      "Epoch 183/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7494 - f1_score: 0.9537 - loss: 0.0513 \n",
      "Epoch 183: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7562 - f1_score: 0.9729 - loss: 0.0346 - val_accuracy: 0.6755 - val_f1_score: 0.9813 - val_loss: 1.1471 - learning_rate: 0.0010\n",
      "Epoch 184/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7954 - f1_score: 0.9573 - loss: 0.0078     \n",
      "Epoch 184: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7881 - f1_score: 0.9748 - loss: 0.0077 - val_accuracy: 0.6821 - val_f1_score: 0.9813 - val_loss: 1.1532 - learning_rate: 0.0010\n",
      "Epoch 185/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8013 - f1_score: 0.9686 - loss: 3.2941e-07\n",
      "Epoch 185: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7995 - f1_score: 0.9725 - loss: 3.4583e-07 - val_accuracy: 0.6810 - val_f1_score: 0.9813 - val_loss: 1.1536 - learning_rate: 0.0010\n",
      "Epoch 186/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7584 - f1_score: 0.9495 - loss: 0.0031     \n",
      "Epoch 186: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7694 - f1_score: 0.9734 - loss: 0.0098 - val_accuracy: 0.6984 - val_f1_score: 0.9813 - val_loss: 1.1639 - learning_rate: 0.0010\n",
      "Epoch 187/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7775 - f1_score: 0.9439 - loss: 0.0305     \n",
      "Epoch 187: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7872 - f1_score: 0.9675 - loss: 0.0301 - val_accuracy: 0.7057 - val_f1_score: 0.9719 - val_loss: 1.1927 - learning_rate: 0.0010\n",
      "Epoch 188/1000\n",
      "\u001b[1m 7/15\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8319 - f1_score: 0.9314 - loss: 7.6026e-10 \n",
      "Epoch 188: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8198 - f1_score: 0.9700 - loss: 3.1399e-09 - val_accuracy: 0.7050 - val_f1_score: 0.9719 - val_loss: 1.2035 - learning_rate: 0.0010\n",
      "Epoch 189/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7930 - f1_score: 0.9733 - loss: 3.4861e-09 \n",
      "Epoch 189: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7902 - f1_score: 0.9850 - loss: 3.7920e-09 - val_accuracy: 0.7057 - val_f1_score: 0.9719 - val_loss: 1.2063 - learning_rate: 0.0010\n",
      "Epoch 190/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8246 - f1_score: 0.9787 - loss: 5.5434e-08\n",
      "Epoch 190: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8233 - f1_score: 0.9800 - loss: 5.7962e-08 - val_accuracy: 0.7050 - val_f1_score: 0.9719 - val_loss: 1.2067 - learning_rate: 0.0010\n",
      "Epoch 191/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7769 - f1_score: 0.9787 - loss: 9.5643e-08\n",
      "Epoch 191: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7785 - f1_score: 0.9800 - loss: 9.3504e-08 - val_accuracy: 0.7050 - val_f1_score: 0.9719 - val_loss: 1.2069 - learning_rate: 0.0010\n",
      "Epoch 192/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7661 - f1_score: 0.9600 - loss: 3.4372e-04 \n",
      "Epoch 192: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7755 - f1_score: 0.9750 - loss: 2.6627e-04 - val_accuracy: 0.7050 - val_f1_score: 0.9719 - val_loss: 1.1599 - learning_rate: 0.0010\n",
      "Epoch 193/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8174 - f1_score: 0.9707 - loss: 2.1225e-08 \n",
      "Epoch 193: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8163 - f1_score: 0.9725 - loss: 2.5049e-08 - val_accuracy: 0.7068 - val_f1_score: 0.9719 - val_loss: 1.1519 - learning_rate: 0.0010\n",
      "Epoch 194/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8017 - f1_score: 0.9544 - loss: 0.0328 \n",
      "Epoch 194: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8009 - f1_score: 0.9679 - loss: 0.0253 - val_accuracy: 0.6793 - val_f1_score: 0.9732 - val_loss: 1.7041 - learning_rate: 0.0010\n",
      "Epoch 195/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8024 - f1_score: 0.9733 - loss: 1.5777e-05\n",
      "Epoch 195: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8014 - f1_score: 0.9750 - loss: 1.7877e-05 - val_accuracy: 0.6710 - val_f1_score: 0.9732 - val_loss: 1.8481 - learning_rate: 0.0010\n",
      "Epoch 196/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7684 - f1_score: 0.9693 - loss: 0.0206    \n",
      "Epoch 196: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7696 - f1_score: 0.9711 - loss: 0.0216 - val_accuracy: 0.6890 - val_f1_score: 0.9719 - val_loss: 1.2940 - learning_rate: 0.0010\n",
      "Epoch 197/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8150 - f1_score: 0.9523 - loss: 0.0040   \n",
      "Epoch 197: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8147 - f1_score: 0.9636 - loss: 0.0052 - val_accuracy: 0.7037 - val_f1_score: 0.9719 - val_loss: 1.4225 - learning_rate: 0.0010\n",
      "Epoch 198/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7926 - f1_score: 0.9440 - loss: 8.8402e-05 \n",
      "Epoch 198: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7997 - f1_score: 0.9637 - loss: 0.0363 - val_accuracy: 0.6901 - val_f1_score: 0.9719 - val_loss: 1.3149 - learning_rate: 0.0010\n",
      "Epoch 199/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8024 - f1_score: 0.9604 - loss: 0.1117    \n",
      "Epoch 199: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\n",
      "Epoch 199: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8016 - f1_score: 0.9625 - loss: 0.1147 - val_accuracy: 0.6633 - val_f1_score: 0.9813 - val_loss: 1.1187 - learning_rate: 0.0010\n",
      "Epoch 200/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7791 - f1_score: 0.9550 - loss: 0.0000e+00 \n",
      "Epoch 200: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7751 - f1_score: 0.9775 - loss: 1.2407e-06 - val_accuracy: 0.6675 - val_f1_score: 0.9813 - val_loss: 1.0972 - learning_rate: 9.0000e-04\n",
      "Epoch 201/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7744 - f1_score: 0.9696 - loss: 0.0213  \n",
      "Epoch 201: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7789 - f1_score: 0.9785 - loss: 0.0173 - val_accuracy: 0.6619 - val_f1_score: 0.9813 - val_loss: 1.1144 - learning_rate: 9.0000e-04\n",
      "Epoch 202/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7845 - f1_score: 0.9717 - loss: 0.0362    \n",
      "Epoch 202: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7853 - f1_score: 0.9766 - loss: 0.0340 - val_accuracy: 0.6602 - val_f1_score: 0.9732 - val_loss: 1.4409 - learning_rate: 9.0000e-04\n",
      "Epoch 203/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8225 - f1_score: 0.9588 - loss: 0.0242     \n",
      "Epoch 203: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8086 - f1_score: 0.9733 - loss: 0.0297 - val_accuracy: 0.6619 - val_f1_score: 0.9732 - val_loss: 1.4665 - learning_rate: 9.0000e-04\n",
      "Epoch 204/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7679 - f1_score: 0.9640 - loss: 1.6193e-05 \n",
      "Epoch 204: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7692 - f1_score: 0.9775 - loss: 1.7360e-05 - val_accuracy: 0.6661 - val_f1_score: 0.9732 - val_loss: 1.3911 - learning_rate: 9.0000e-04\n",
      "Epoch 205/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7879 - f1_score: 0.9591 - loss: 0.0470\n",
      "Epoch 205: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7881 - f1_score: 0.9612 - loss: 0.0474 - val_accuracy: 0.7016 - val_f1_score: 0.9732 - val_loss: 1.1930 - learning_rate: 9.0000e-04\n",
      "Epoch 206/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7725 - f1_score: 0.9753 - loss: 0.0649     \n",
      "Epoch 206: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7799 - f1_score: 0.9816 - loss: 0.0764 - val_accuracy: 0.7169 - val_f1_score: 0.9722 - val_loss: 1.1602 - learning_rate: 9.0000e-04\n",
      "Epoch 207/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7983 - f1_score: 0.9613 - loss: 0.0843     \n",
      "Epoch 207: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8084 - f1_score: 0.9751 - loss: 0.0670 - val_accuracy: 0.7478 - val_f1_score: 0.9732 - val_loss: 1.7097 - learning_rate: 9.0000e-04\n",
      "Epoch 208/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8085 - f1_score: 0.9800 - loss: 2.8712e-04\n",
      "Epoch 208: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8122 - f1_score: 0.9850 - loss: 5.7064e-04 - val_accuracy: 0.7635 - val_f1_score: 0.9732 - val_loss: 1.9276 - learning_rate: 9.0000e-04\n",
      "Epoch 209/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8600 - f1_score: 0.9569 - loss: 1.2169e-08\n",
      "Epoch 209: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8585 - f1_score: 0.9650 - loss: 7.2095e-08 - val_accuracy: 0.7694 - val_f1_score: 0.9732 - val_loss: 1.9496 - learning_rate: 9.0000e-04\n",
      "Epoch 210/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8672 - f1_score: 0.9767 - loss: 1.1090e-09 \n",
      "Epoch 210: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8608 - f1_score: 0.9825 - loss: 1.3003e-09 - val_accuracy: 0.7697 - val_f1_score: 0.9732 - val_loss: 1.9570 - learning_rate: 9.0000e-04\n",
      "Epoch 211/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8529 - f1_score: 0.9689 - loss: 1.3797e-09 \n",
      "Epoch 211: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8421 - f1_score: 0.9825 - loss: 4.6997e-09 - val_accuracy: 0.7701 - val_f1_score: 0.9722 - val_loss: 1.9604 - learning_rate: 9.0000e-04\n",
      "Epoch 212/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8476 - f1_score: 0.9640 - loss: 1.3591e-07 \n",
      "Epoch 212: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8451 - f1_score: 0.9775 - loss: 1.2083e-07 - val_accuracy: 0.7704 - val_f1_score: 0.9722 - val_loss: 1.9611 - learning_rate: 9.0000e-04\n",
      "Epoch 213/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8553 - f1_score: 0.9846 - loss: 2.2800e-07\n",
      "Epoch 213: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8533 - f1_score: 0.9875 - loss: 4.2858e-07 - val_accuracy: 0.7704 - val_f1_score: 0.9722 - val_loss: 1.9611 - learning_rate: 9.0000e-04\n",
      "Epoch 214/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8327 - f1_score: 0.9745 - loss: 6.5411e-06 \n",
      "Epoch 214: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8378 - f1_score: 0.9825 - loss: 6.3579e-06 - val_accuracy: 0.7704 - val_f1_score: 0.9722 - val_loss: 1.9613 - learning_rate: 9.0000e-04\n",
      "Epoch 215/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8743 - f1_score: 0.9520 - loss: 9.8738e-05 \n",
      "Epoch 215: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8646 - f1_score: 0.9700 - loss: 1.2130e-04 - val_accuracy: 0.7739 - val_f1_score: 0.9722 - val_loss: 1.9641 - learning_rate: 9.0000e-04\n",
      "Epoch 216/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8392 - f1_score: 0.9856 - loss: 0.0072     \n",
      "Epoch 216: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8391 - f1_score: 0.9879 - loss: 0.0080 - val_accuracy: 0.7743 - val_f1_score: 0.9722 - val_loss: 1.5783 - learning_rate: 9.0000e-04\n",
      "Epoch 217/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8375 - f1_score: 0.9740 - loss: 0.0489     \n",
      "Epoch 217: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8380 - f1_score: 0.9753 - loss: 0.0517 - val_accuracy: 0.7701 - val_f1_score: 0.9380 - val_loss: 1.4446 - learning_rate: 9.0000e-04\n",
      "Epoch 218/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8514 - f1_score: 0.9914 - loss: 2.9357e-08 \n",
      "Epoch 218: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8516 - f1_score: 0.9925 - loss: 2.7275e-08 - val_accuracy: 0.7597 - val_f1_score: 0.9195 - val_loss: 1.6407 - learning_rate: 9.0000e-04\n",
      "Epoch 219/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8281 - f1_score: 0.9687 - loss: 0.0578     \n",
      "Epoch 219: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8292 - f1_score: 0.9705 - loss: 0.0578 - val_accuracy: 0.7579 - val_f1_score: 0.9186 - val_loss: 2.2646 - learning_rate: 9.0000e-04\n",
      "Epoch 220/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8425 - f1_score: 0.9846 - loss: 0.0712     \n",
      "Epoch 220: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8428 - f1_score: 0.9855 - loss: 0.0712 - val_accuracy: 0.7482 - val_f1_score: 0.9012 - val_loss: 3.2315 - learning_rate: 9.0000e-04\n",
      "Epoch 221/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8322 - f1_score: 0.9683 - loss: 0.1397     \n",
      "Epoch 221: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8327 - f1_score: 0.9734 - loss: 0.1435 - val_accuracy: 0.7572 - val_f1_score: 0.9125 - val_loss: 2.2514 - learning_rate: 9.0000e-04\n",
      "Epoch 222/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8573 - f1_score: 0.9600 - loss: 0.1108     \n",
      "Epoch 222: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8573 - f1_score: 0.9690 - loss: 0.1000 - val_accuracy: 0.7732 - val_f1_score: 0.9125 - val_loss: 2.1813 - learning_rate: 9.0000e-04\n",
      "Epoch 223/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8594 - f1_score: 0.9717 - loss: 0.1584     \n",
      "Epoch 223: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8597 - f1_score: 0.9747 - loss: 0.1590 - val_accuracy: 0.7850 - val_f1_score: 0.9193 - val_loss: 1.8265 - learning_rate: 9.0000e-04\n",
      "Epoch 224/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9463 - f1_score: 0.6400 - loss: 0.0000e+00\n",
      "Epoch 224: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8859 - f1_score: 0.9762 - loss: 0.0242 - val_accuracy: 0.8003 - val_f1_score: 0.9193 - val_loss: 2.0337 - learning_rate: 9.0000e-04\n",
      "Epoch 225/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8736 - f1_score: 0.9865 - loss: 0.0196     \n",
      "Epoch 225: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8747 - f1_score: 0.9887 - loss: 0.0232 - val_accuracy: 0.8000 - val_f1_score: 0.9193 - val_loss: 2.0824 - learning_rate: 9.0000e-04\n",
      "Epoch 226/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8598 - f1_score: 0.9552 - loss: 0.1157     \n",
      "Epoch 226: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8668 - f1_score: 0.9703 - loss: 0.1257 - val_accuracy: 0.7923 - val_f1_score: 0.9629 - val_loss: 1.8393 - learning_rate: 9.0000e-04\n",
      "Epoch 227/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8907 - f1_score: 0.9827 - loss: 0.1213     \n",
      "Epoch 227: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8881 - f1_score: 0.9852 - loss: 0.1303 - val_accuracy: 0.7809 - val_f1_score: 0.9193 - val_loss: 2.2442 - learning_rate: 9.0000e-04\n",
      "Epoch 228/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8162 - f1_score: 0.6000 - loss: 0.1592\n",
      "Epoch 228: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8354 - f1_score: 0.9413 - loss: 0.1973 - val_accuracy: 0.7997 - val_f1_score: 0.9177 - val_loss: 1.9034 - learning_rate: 9.0000e-04\n",
      "Epoch 229/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8560 - f1_score: 0.9546 - loss: 0.5937     \n",
      "Epoch 229: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8584 - f1_score: 0.9623 - loss: 0.5326 - val_accuracy: 0.7739 - val_f1_score: 0.9189 - val_loss: 2.5220 - learning_rate: 9.0000e-04\n",
      "Epoch 230/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8710 - f1_score: 0.9698 - loss: 0.0874     \n",
      "Epoch 230: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8701 - f1_score: 0.9747 - loss: 0.0818 - val_accuracy: 0.7791 - val_f1_score: 0.9640 - val_loss: 1.1056 - learning_rate: 9.0000e-04\n",
      "Epoch 231/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8715 - f1_score: 0.9668 - loss: 1.0228 \n",
      "Epoch 231: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8732 - f1_score: 0.9729 - loss: 0.8475 - val_accuracy: 0.8097 - val_f1_score: 0.9778 - val_loss: 0.6961 - learning_rate: 9.0000e-04\n",
      "Epoch 232/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9010 - f1_score: 0.9762 - loss: 0.0209     \n",
      "Epoch 232: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9009 - f1_score: 0.9788 - loss: 0.0243 - val_accuracy: 0.8108 - val_f1_score: 0.9778 - val_loss: 0.6804 - learning_rate: 9.0000e-04\n",
      "Epoch 233/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8949 - f1_score: 0.9778 - loss: 0.0143      \n",
      "Epoch 233: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8955 - f1_score: 0.9803 - loss: 0.0143 - val_accuracy: 0.7857 - val_f1_score: 0.9778 - val_loss: 0.6535 - learning_rate: 9.0000e-04\n",
      "Epoch 234/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8879 - f1_score: 0.9778 - loss: 8.1655e-04 \n",
      "Epoch 234: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8865 - f1_score: 0.9859 - loss: 0.0295 - val_accuracy: 0.7906 - val_f1_score: 0.9778 - val_loss: 0.6905 - learning_rate: 9.0000e-04\n",
      "Epoch 235/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9087 - f1_score: 0.9568 - loss: 0.2161     \n",
      "Epoch 235: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9030 - f1_score: 0.9681 - loss: 0.1992 - val_accuracy: 0.7541 - val_f1_score: 0.9543 - val_loss: 0.8695 - learning_rate: 9.0000e-04\n",
      "Epoch 236/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8824 - f1_score: 0.9563 - loss: 0.0153     \n",
      "Epoch 236: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8777 - f1_score: 0.9692 - loss: 0.0124 - val_accuracy: 0.7576 - val_f1_score: 0.9622 - val_loss: 0.9130 - learning_rate: 9.0000e-04\n",
      "Epoch 237/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8514 - f1_score: 0.9653 - loss: 0.0163     \n",
      "Epoch 237: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8561 - f1_score: 0.9728 - loss: 0.0269 - val_accuracy: 0.7750 - val_f1_score: 0.9733 - val_loss: 0.9167 - learning_rate: 9.0000e-04\n",
      "Epoch 238/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8758 - f1_score: 0.9664 - loss: 0.0201     \n",
      "Epoch 238: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8763 - f1_score: 0.9741 - loss: 0.0185 - val_accuracy: 0.7875 - val_f1_score: 0.9725 - val_loss: 0.9424 - learning_rate: 9.0000e-04\n",
      "Epoch 239/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8988 - f1_score: 0.9645 - loss: 0.1385     \n",
      "Epoch 239: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8995 - f1_score: 0.9684 - loss: 0.1344 - val_accuracy: 0.8167 - val_f1_score: 0.9725 - val_loss: 0.6245 - learning_rate: 9.0000e-04\n",
      "Epoch 240/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9300 - f1_score: 0.9600 - loss: 3.1237e-08 \n",
      "Epoch 240: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9220 - f1_score: 0.9725 - loss: 4.0124e-08 - val_accuracy: 0.8191 - val_f1_score: 0.9828 - val_loss: 0.4628 - learning_rate: 9.0000e-04\n",
      "Epoch 241/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8938 - f1_score: 0.9813 - loss: 8.2481e-10 \n",
      "Epoch 241: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8941 - f1_score: 0.9825 - loss: 7.8946e-10 - val_accuracy: 0.8163 - val_f1_score: 0.9828 - val_loss: 0.4624 - learning_rate: 9.0000e-04\n",
      "Epoch 242/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8872 - f1_score: 0.9723 - loss: 7.1938e-08 \n",
      "Epoch 242: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8892 - f1_score: 0.9775 - loss: 1.0752e-07 - val_accuracy: 0.8146 - val_f1_score: 0.9828 - val_loss: 0.4622 - learning_rate: 9.0000e-04\n",
      "Epoch 243/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9177 - f1_score: 0.9800 - loss: 2.4259e-08 \n",
      "Epoch 243: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9145 - f1_score: 0.9850 - loss: 3.9998e-08 - val_accuracy: 0.8143 - val_f1_score: 0.9828 - val_loss: 0.4623 - learning_rate: 9.0000e-04\n",
      "Epoch 244/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9261 - f1_score: 0.9778 - loss: 0.0000e+00 \n",
      "Epoch 244: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9174 - f1_score: 0.9875 - loss: 1.3940e-07 - val_accuracy: 0.8146 - val_f1_score: 0.9828 - val_loss: 0.4624 - learning_rate: 9.0000e-04\n",
      "Epoch 245/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9156 - f1_score: 0.9655 - loss: 0.0264     \n",
      "Epoch 245: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9154 - f1_score: 0.9749 - loss: 0.0404 - val_accuracy: 0.8490 - val_f1_score: 0.9823 - val_loss: 0.2784 - learning_rate: 9.0000e-04\n",
      "Epoch 246/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9060 - f1_score: 0.9586 - loss: 0.0233     \n",
      "Epoch 246: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9085 - f1_score: 0.9683 - loss: 0.0273 - val_accuracy: 0.8264 - val_f1_score: 0.9541 - val_loss: 0.7593 - learning_rate: 9.0000e-04\n",
      "Epoch 247/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9358 - f1_score: 0.9830 - loss: 0.0843     \n",
      "Epoch 247: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9336 - f1_score: 0.9857 - loss: 0.0930 - val_accuracy: 0.8490 - val_f1_score: 0.9528 - val_loss: 0.7257 - learning_rate: 9.0000e-04\n",
      "Epoch 248/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9235 - f1_score: 0.9729 - loss: 0.0635     \n",
      "Epoch 248: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9245 - f1_score: 0.9801 - loss: 0.0726 - val_accuracy: 0.8529 - val_f1_score: 0.9719 - val_loss: 0.4312 - learning_rate: 9.0000e-04\n",
      "Epoch 249/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9325 - f1_score: 0.9661 - loss: 0.0302     \n",
      "Epoch 249: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9311 - f1_score: 0.9760 - loss: 0.0388 - val_accuracy: 0.8570 - val_f1_score: 0.9526 - val_loss: 0.9260 - learning_rate: 9.0000e-04\n",
      "Epoch 250/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9187 - f1_score: 0.9573 - loss: 0.1018     \n",
      "Epoch 250: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9207 - f1_score: 0.9685 - loss: 0.1618 - val_accuracy: 0.8490 - val_f1_score: 0.9771 - val_loss: 0.8264 - learning_rate: 9.0000e-04\n",
      "Epoch 251/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9351 - f1_score: 0.9634 - loss: 0.0164      \n",
      "Epoch 251: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9288 - f1_score: 0.9763 - loss: 0.0318 - val_accuracy: 0.8539 - val_f1_score: 0.9752 - val_loss: 0.2138 - learning_rate: 9.0000e-04\n",
      "Epoch 252/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9071 - f1_score: 0.9707 - loss: 0.0380 \n",
      "Epoch 252: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9087 - f1_score: 0.9754 - loss: 0.0516 - val_accuracy: 0.8421 - val_f1_score: 0.9919 - val_loss: 0.1312 - learning_rate: 9.0000e-04\n",
      "Epoch 253/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9113 - f1_score: 0.9833 - loss: 0.0149     \n",
      "Epoch 253: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9103 - f1_score: 0.9860 - loss: 0.0176 - val_accuracy: 0.8327 - val_f1_score: 0.9588 - val_loss: 1.7065 - learning_rate: 9.0000e-04\n",
      "Epoch 254/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8970 - f1_score: 0.9558 - loss: 0.0555     \n",
      "Epoch 254: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9022 - f1_score: 0.9701 - loss: 0.0513 - val_accuracy: 0.8515 - val_f1_score: 0.9717 - val_loss: 2.3763 - learning_rate: 9.0000e-04\n",
      "Epoch 255/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9129 - f1_score: 0.9875 - loss: 4.9746e-04 \n",
      "Epoch 255: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9123 - f1_score: 0.9894 - loss: 0.0015 - val_accuracy: 0.8313 - val_f1_score: 0.9671 - val_loss: 0.9018 - learning_rate: 9.0000e-04\n",
      "Epoch 256/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9170 - f1_score: 0.9600 - loss: 5.9259e-04 \n",
      "Epoch 256: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9155 - f1_score: 0.9675 - loss: 6.1249e-04 - val_accuracy: 0.8557 - val_f1_score: 0.9552 - val_loss: 1.7888 - learning_rate: 9.0000e-04\n",
      "Epoch 257/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9081 - f1_score: 0.9579 - loss: 0.0142     \n",
      "Epoch 257: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9101 - f1_score: 0.9679 - loss: 0.0138 - val_accuracy: 0.8654 - val_f1_score: 0.9552 - val_loss: 2.7336 - learning_rate: 9.0000e-04\n",
      "Epoch 258/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9524 - f1_score: 0.9487 - loss: 1.0687     \n",
      "Epoch 258: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9445 - f1_score: 0.9620 - loss: 0.9294 - val_accuracy: 0.8480 - val_f1_score: 0.9815 - val_loss: 0.2492 - learning_rate: 9.0000e-04\n",
      "Epoch 259/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8776 - f1_score: 0.9703 - loss: 0.0362     \n",
      "Epoch 259: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8879 - f1_score: 0.9806 - loss: 0.0432 - val_accuracy: 0.8574 - val_f1_score: 0.9916 - val_loss: 0.0479 - learning_rate: 9.0000e-04\n",
      "Epoch 260/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9190 - f1_score: 0.9500 - loss: 0.0000e+00 \n",
      "Epoch 260: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9184 - f1_score: 0.9745 - loss: 0.0156 - val_accuracy: 0.8616 - val_f1_score: 0.9916 - val_loss: 0.0658 - learning_rate: 9.0000e-04\n",
      "Epoch 261/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9170 - f1_score: 0.9675 - loss: 0.0468    \n",
      "Epoch 261: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9186 - f1_score: 0.9711 - loss: 0.0445 - val_accuracy: 0.8692 - val_f1_score: 0.9826 - val_loss: 0.4461 - learning_rate: 9.0000e-04\n",
      "Epoch 262/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9335 - f1_score: 0.9612 - loss: 0.2025     \n",
      "Epoch 262: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9388 - f1_score: 0.9741 - loss: 0.2142 - val_accuracy: 0.8570 - val_f1_score: 0.9910 - val_loss: 0.4682 - learning_rate: 9.0000e-04\n",
      "Epoch 263/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9295 - f1_score: 0.9674 - loss: 0.0245     \n",
      "Epoch 263: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9360 - f1_score: 0.9806 - loss: 0.0343 - val_accuracy: 0.8602 - val_f1_score: 0.9910 - val_loss: 0.4528 - learning_rate: 9.0000e-04\n",
      "Epoch 264/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9390 - f1_score: 0.9774 - loss: 0.0069     \n",
      "Epoch 264: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9424 - f1_score: 0.9838 - loss: 0.0105 - val_accuracy: 0.8626 - val_f1_score: 0.9910 - val_loss: 0.3952 - learning_rate: 9.0000e-04\n",
      "Epoch 265/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9407 - f1_score: 0.9825 - loss: 0.0167    \n",
      "Epoch 265: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9418 - f1_score: 0.9845 - loss: 0.0284 - val_accuracy: 0.8560 - val_f1_score: 0.9910 - val_loss: 0.3523 - learning_rate: 9.0000e-04\n",
      "Epoch 266/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9479 - f1_score: 0.9605 - loss: 0.1058     \n",
      "Epoch 266: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9477 - f1_score: 0.9745 - loss: 0.0940 - val_accuracy: 0.8501 - val_f1_score: 0.9736 - val_loss: 0.4883 - learning_rate: 9.0000e-04\n",
      "Epoch 267/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9345 - f1_score: 0.9745 - loss: 3.1323e-05 \n",
      "Epoch 267: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9350 - f1_score: 0.9825 - loss: 2.4179e-05 - val_accuracy: 0.8494 - val_f1_score: 0.9604 - val_loss: 0.8778 - learning_rate: 9.0000e-04\n",
      "Epoch 268/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9515 - f1_score: 0.9767 - loss: 0.0000e+00\n",
      "Epoch 268: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9503 - f1_score: 0.9822 - loss: 0.0107 - val_accuracy: 0.8494 - val_f1_score: 0.9718 - val_loss: 0.7187 - learning_rate: 9.0000e-04\n",
      "Epoch 269/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9564 - f1_score: 0.9720 - loss: 8.5709e-07 \n",
      "Epoch 269: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9532 - f1_score: 0.9808 - loss: 0.0392 - val_accuracy: 0.8887 - val_f1_score: 0.9781 - val_loss: 0.4434 - learning_rate: 9.0000e-04\n",
      "Epoch 270/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9582 - f1_score: 0.9440 - loss: 7.4287e-07 \n",
      "Epoch 270: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9567 - f1_score: 0.9650 - loss: 5.2257e-05 - val_accuracy: 0.8831 - val_f1_score: 0.9693 - val_loss: 0.4353 - learning_rate: 9.0000e-04\n",
      "Epoch 271/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9638 - f1_score: 0.9598 - loss: 0.1319\n",
      "Epoch 271: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9641 - f1_score: 0.9642 - loss: 0.1286 - val_accuracy: 0.9106 - val_f1_score: 0.9781 - val_loss: 0.3540 - learning_rate: 9.0000e-04\n",
      "Epoch 272/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9748 - f1_score: 0.9890 - loss: 0.0263    \n",
      "Epoch 272: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9724 - f1_score: 0.9906 - loss: 0.0290 - val_accuracy: 0.8970 - val_f1_score: 0.9826 - val_loss: 0.3181 - learning_rate: 9.0000e-04\n",
      "Epoch 273/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9696 - f1_score: 0.9680 - loss: 3.1502e-10 \n",
      "Epoch 273: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9673 - f1_score: 0.9800 - loss: 3.0439e-10 - val_accuracy: 0.8939 - val_f1_score: 0.9709 - val_loss: 0.6126 - learning_rate: 9.0000e-04\n",
      "Epoch 274/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9648 - f1_score: 0.9664 - loss: 0.0557    \n",
      "Epoch 274: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9627 - f1_score: 0.9762 - loss: 0.0854 - val_accuracy: 0.9047 - val_f1_score: 0.9660 - val_loss: 0.9921 - learning_rate: 9.0000e-04\n",
      "Epoch 275/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9610 - f1_score: 0.9800 - loss: 1.1273e-06 \n",
      "Epoch 275: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9605 - f1_score: 0.9875 - loss: 2.2384e-06 - val_accuracy: 0.9047 - val_f1_score: 0.9660 - val_loss: 1.3008 - learning_rate: 9.0000e-04\n",
      "Epoch 276/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9730 - f1_score: 0.9714 - loss: 2.6639e-06\n",
      "Epoch 276: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9724 - f1_score: 0.9750 - loss: 2.7205e-06 - val_accuracy: 0.9054 - val_f1_score: 0.9660 - val_loss: 1.3741 - learning_rate: 9.0000e-04\n",
      "Epoch 277/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9483 - f1_score: 0.9670 - loss: 0.1652    \n",
      "Epoch 277: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9501 - f1_score: 0.9703 - loss: 0.1613 - val_accuracy: 0.9057 - val_f1_score: 0.9557 - val_loss: 2.0008 - learning_rate: 9.0000e-04\n",
      "Epoch 278/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9621 - f1_score: 0.9592 - loss: 0.3747\n",
      "Epoch 278: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9619 - f1_score: 0.9613 - loss: 0.3698 - val_accuracy: 0.8894 - val_f1_score: 0.9491 - val_loss: 1.7564 - learning_rate: 9.0000e-04\n",
      "Epoch 279/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9578 - f1_score: 0.9743 - loss: 3.7405e-06 \n",
      "Epoch 279: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9580 - f1_score: 0.9775 - loss: 3.7432e-06 - val_accuracy: 0.8859 - val_f1_score: 0.9528 - val_loss: 2.3272 - learning_rate: 9.0000e-04\n",
      "Epoch 280/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9555 - f1_score: 0.9822 - loss: 0.0000e+00 \n",
      "Epoch 280: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9566 - f1_score: 0.9900 - loss: 0.0000e+00 - val_accuracy: 0.8856 - val_f1_score: 0.9528 - val_loss: 2.5091 - learning_rate: 9.0000e-04\n",
      "Epoch 281/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9667 - f1_score: 0.9667 - loss: 0.0172     \n",
      "Epoch 281: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9635 - f1_score: 0.9763 - loss: 0.0348 - val_accuracy: 0.8936 - val_f1_score: 0.9603 - val_loss: 2.4861 - learning_rate: 9.0000e-04\n",
      "Epoch 282/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9525 - f1_score: 0.9754 - loss: 1.8117e-08 \n",
      "Epoch 282: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9519 - f1_score: 0.9800 - loss: 1.6142e-08 - val_accuracy: 0.8883 - val_f1_score: 0.9603 - val_loss: 2.9075 - learning_rate: 9.0000e-04\n",
      "Epoch 283/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9556 - f1_score: 0.9700 - loss: 2.4537e-08 \n",
      "Epoch 283: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9557 - f1_score: 0.9775 - loss: 2.6501e-08 - val_accuracy: 0.8870 - val_f1_score: 0.9523 - val_loss: 3.1868 - learning_rate: 9.0000e-04\n",
      "Epoch 284/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9281 - f1_score: 0.9680 - loss: 0.0000e+00 \n",
      "Epoch 284: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9323 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.8870 - val_f1_score: 0.9523 - val_loss: 3.2723 - learning_rate: 9.0000e-04\n",
      "Epoch 285/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9340 - f1_score: 0.9673 - loss: 2.8923e-10 \n",
      "Epoch 285: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9364 - f1_score: 0.9775 - loss: 3.7152e-10 - val_accuracy: 0.8873 - val_f1_score: 0.9523 - val_loss: 3.2906 - learning_rate: 9.0000e-04\n",
      "Epoch 286/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9565 - f1_score: 0.9700 - loss: 0.0000e+00 \n",
      "Epoch 286: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9531 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.8873 - val_f1_score: 0.9523 - val_loss: 3.2941 - learning_rate: 9.0000e-04\n",
      "Epoch 287/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9482 - f1_score: 0.9700 - loss: 5.3302e-08\n",
      "Epoch 287: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9472 - f1_score: 0.9775 - loss: 1.7764e-07 - val_accuracy: 0.8873 - val_f1_score: 0.9523 - val_loss: 3.2938 - learning_rate: 9.0000e-04\n",
      "Epoch 288/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9606 - f1_score: 0.9680 - loss: 2.9358e-07 \n",
      "Epoch 288: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9548 - f1_score: 0.9800 - loss: 1.0378e-05 - val_accuracy: 0.8873 - val_f1_score: 0.9523 - val_loss: 3.2906 - learning_rate: 9.0000e-04\n",
      "Epoch 289/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9418 - f1_score: 0.9815 - loss: 1.4649e-06\n",
      "Epoch 289: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9420 - f1_score: 0.9850 - loss: 1.2691e-06 - val_accuracy: 0.8883 - val_f1_score: 0.9523 - val_loss: 3.2865 - learning_rate: 9.0000e-04\n",
      "Epoch 290/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9452 - f1_score: 0.9723 - loss: 2.6844e-04\n",
      "Epoch 290: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9454 - f1_score: 0.9775 - loss: 2.5998e-04 - val_accuracy: 0.8939 - val_f1_score: 0.9603 - val_loss: 2.8835 - learning_rate: 9.0000e-04\n",
      "Epoch 291/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9556 - f1_score: 0.9686 - loss: 0.0000e+00\n",
      "Epoch 291: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9543 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.8943 - val_f1_score: 0.9603 - val_loss: 2.8330 - learning_rate: 9.0000e-04\n",
      "Epoch 292/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9316 - f1_score: 0.9511 - loss: 2.5069e-08 \n",
      "Epoch 292: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9376 - f1_score: 0.9725 - loss: 2.8619e-08 - val_accuracy: 0.8957 - val_f1_score: 0.9603 - val_loss: 2.8219 - learning_rate: 9.0000e-04\n",
      "Epoch 293/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9442 - f1_score: 0.9675 - loss: 0.0794  \n",
      "Epoch 293: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9491 - f1_score: 0.9768 - loss: 0.0646 - val_accuracy: 0.9061 - val_f1_score: 0.9599 - val_loss: 2.8867 - learning_rate: 9.0000e-04\n",
      "Epoch 294/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9438 - f1_score: 0.6800 - loss: 0.0000e+00\n",
      "Epoch 294: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9598 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9092 - val_f1_score: 0.9599 - val_loss: 3.0633 - learning_rate: 9.0000e-04\n",
      "Epoch 295/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9643 - f1_score: 0.9662 - loss: 0.0000e+00 \n",
      "Epoch 295: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9637 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_f1_score: 0.9599 - val_loss: 3.1007 - learning_rate: 9.0000e-04\n",
      "Epoch 296/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9700 - f1_score: 0.9908 - loss: 0.0000e+00 \n",
      "Epoch 296: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9690 - f1_score: 0.9925 - loss: 0.0000e+00 - val_accuracy: 0.9099 - val_f1_score: 0.9599 - val_loss: 3.1085 - learning_rate: 9.0000e-04\n",
      "Epoch 297/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9626 - f1_score: 0.9805 - loss: 0.0340     \n",
      "Epoch 297: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9619 - f1_score: 0.9857 - loss: 0.0437 - val_accuracy: 0.9047 - val_f1_score: 0.9675 - val_loss: 2.6014 - learning_rate: 9.0000e-04\n",
      "Epoch 298/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9632 - f1_score: 0.9800 - loss: 3.6608e-08 \n",
      "Epoch 298: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9620 - f1_score: 0.9850 - loss: 2.9999e-08 - val_accuracy: 0.9103 - val_f1_score: 0.9620 - val_loss: 2.6966 - learning_rate: 9.0000e-04\n",
      "Epoch 299/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9887 - f1_score: 0.8000 - loss: 0.0000e+00\n",
      "Epoch 299: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\n",
      "Epoch 299: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9584 - f1_score: 0.9875 - loss: 3.2251e-10 - val_accuracy: 0.9085 - val_f1_score: 0.9620 - val_loss: 2.7180 - learning_rate: 9.0000e-04\n",
      "Epoch 300/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9656 - f1_score: 0.9653 - loss: 0.0000e+00 \n",
      "Epoch 300: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9651 - f1_score: 0.9675 - loss: 0.0000e+00 - val_accuracy: 0.9085 - val_f1_score: 0.9620 - val_loss: 2.7224 - learning_rate: 8.1000e-04\n",
      "Epoch 301/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9575 - f1_score: 0.9833 - loss: 0.0000e+00 \n",
      "Epoch 301: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9576 - f1_score: 0.9875 - loss: 3.2905e-05 - val_accuracy: 0.9085 - val_f1_score: 0.9620 - val_loss: 2.7260 - learning_rate: 8.1000e-04\n",
      "Epoch 302/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9636 - f1_score: 0.9646 - loss: 0.0032     \n",
      "Epoch 302: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9642 - f1_score: 0.9729 - loss: 0.0028 - val_accuracy: 0.9224 - val_f1_score: 0.9675 - val_loss: 2.5358 - learning_rate: 8.1000e-04\n",
      "Epoch 303/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9721 - f1_score: 0.9588 - loss: 0.0013     \n",
      "Epoch 303: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9721 - f1_score: 0.9612 - loss: 0.0014 - val_accuracy: 0.9301 - val_f1_score: 0.9675 - val_loss: 2.0897 - learning_rate: 8.1000e-04\n",
      "Epoch 304/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9643 - f1_score: 0.9714 - loss: 0.0000e+00 \n",
      "Epoch 304: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9640 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9245 - val_f1_score: 0.9791 - val_loss: 1.9083 - learning_rate: 8.1000e-04\n",
      "Epoch 305/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9761 - f1_score: 0.9891 - loss: 0.0000e+00 \n",
      "Epoch 305: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9744 - f1_score: 0.9925 - loss: 0.0000e+00 - val_accuracy: 0.9228 - val_f1_score: 0.9791 - val_loss: 1.9334 - learning_rate: 8.1000e-04\n",
      "Epoch 306/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9676 - f1_score: 0.9673 - loss: 0.0000e+00 \n",
      "Epoch 306: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9655 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9228 - val_f1_score: 0.9791 - val_loss: 1.9388 - learning_rate: 8.1000e-04\n",
      "Epoch 307/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9649 - f1_score: 0.9760 - loss: 0.0000e+00 \n",
      "Epoch 307: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9652 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9228 - val_f1_score: 0.9791 - val_loss: 1.9400 - learning_rate: 8.1000e-04\n",
      "Epoch 308/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9662 - f1_score: 0.9511 - loss: 0.0000e+00 \n",
      "Epoch 308: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9645 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9228 - val_f1_score: 0.9791 - val_loss: 1.9403 - learning_rate: 8.1000e-04\n",
      "Epoch 309/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9607 - f1_score: 0.9813 - loss: 0.0000e+00 \n",
      "Epoch 309: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9611 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9224 - val_f1_score: 0.9791 - val_loss: 1.9403 - learning_rate: 8.1000e-04\n",
      "Epoch 310/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9579 - f1_score: 0.9686 - loss: 0.0000e+00 \n",
      "Epoch 310: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9586 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9224 - val_f1_score: 0.9791 - val_loss: 1.9403 - learning_rate: 8.1000e-04\n",
      "Epoch 311/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9739 - f1_score: 0.9855 - loss: 0.0000e+00 \n",
      "Epoch 311: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9740 - f1_score: 0.9900 - loss: 0.0000e+00 - val_accuracy: 0.9224 - val_f1_score: 0.9791 - val_loss: 1.9403 - learning_rate: 8.1000e-04\n",
      "Epoch 312/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9768 - f1_score: 0.9745 - loss: 0.0000e+00 \n",
      "Epoch 312: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9735 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9224 - val_f1_score: 0.9791 - val_loss: 1.9403 - learning_rate: 8.1000e-04\n",
      "Epoch 313/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9759 - f1_score: 0.9733 - loss: 0.0000e+00 \n",
      "Epoch 313: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9728 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9224 - val_f1_score: 0.9791 - val_loss: 1.9403 - learning_rate: 8.1000e-04\n",
      "Epoch 314/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9719 - f1_score: 0.9667 - loss: 4.3668e-08 \n",
      "Epoch 314: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9677 - f1_score: 0.9750 - loss: 6.6284e-08 - val_accuracy: 0.9224 - val_f1_score: 0.9791 - val_loss: 1.9403 - learning_rate: 8.1000e-04\n",
      "Epoch 315/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9657 - f1_score: 0.9582 - loss: 0.0040     \n",
      "Epoch 315: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9645 - f1_score: 0.9730 - loss: 0.0038 - val_accuracy: 0.9214 - val_f1_score: 0.9626 - val_loss: 3.0580 - learning_rate: 8.1000e-04\n",
      "Epoch 316/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9676 - f1_score: 0.9554 - loss: 0.1918     \n",
      "Epoch 316: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9665 - f1_score: 0.9660 - loss: 0.1696 - val_accuracy: 0.9224 - val_f1_score: 0.9791 - val_loss: 1.7280 - learning_rate: 8.1000e-04\n",
      "Epoch 317/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9591 - f1_score: 0.9709 - loss: 0.0000e+00 \n",
      "Epoch 317: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9593 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6565 - learning_rate: 8.1000e-04\n",
      "Epoch 318/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9692 - f1_score: 0.9714 - loss: 0.0000e+00 \n",
      "Epoch 318: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9688 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6505 - learning_rate: 8.1000e-04\n",
      "Epoch 319/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9571 - f1_score: 0.9673 - loss: 0.0000e+00 \n",
      "Epoch 319: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9578 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6495 - learning_rate: 8.1000e-04\n",
      "Epoch 320/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9558 - f1_score: 0.9745 - loss: 0.0000e+00 \n",
      "Epoch 320: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9575 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6492 - learning_rate: 8.1000e-04\n",
      "Epoch 321/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9527 - f1_score: 0.9815 - loss: 0.0000e+00 \n",
      "Epoch 321: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9536 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6492 - learning_rate: 8.1000e-04\n",
      "Epoch 322/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9644 - f1_score: 0.9846 - loss: 0.0000e+00 \n",
      "Epoch 322: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9634 - f1_score: 0.9875 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6492 - learning_rate: 8.1000e-04\n",
      "Epoch 323/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9560 - f1_score: 0.9673 - loss: 0.0000e+00 \n",
      "Epoch 323: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9581 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6492 - learning_rate: 8.1000e-04\n",
      "Epoch 324/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9692 - f1_score: 0.9653 - loss: 0.0000e+00 \n",
      "Epoch 324: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9690 - f1_score: 0.9675 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6492 - learning_rate: 8.1000e-04\n",
      "Epoch 325/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9630 - f1_score: 0.9745 - loss: 0.0000e+00 \n",
      "Epoch 325: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9633 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6492 - learning_rate: 8.1000e-04\n",
      "Epoch 326/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9681 - f1_score: 0.9914 - loss: 0.0000e+00 \n",
      "Epoch 326: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9673 - f1_score: 0.9925 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6492 - learning_rate: 8.1000e-04\n",
      "Epoch 327/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9460 - f1_score: 0.9511 - loss: 0.0000e+00 \n",
      "Epoch 327: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9501 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6492 - learning_rate: 8.1000e-04\n",
      "Epoch 328/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9573 - f1_score: 0.9800 - loss: 0.0000e+00 \n",
      "Epoch 328: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9578 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6492 - learning_rate: 8.1000e-04\n",
      "Epoch 329/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9770 - f1_score: 0.9709 - loss: 0.0000e+00 \n",
      "Epoch 329: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9732 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6492 - learning_rate: 8.1000e-04\n",
      "Epoch 330/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9638 - f1_score: 0.9760 - loss: 1.6417e-07 \n",
      "Epoch 330: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9635 - f1_score: 0.9775 - loss: 1.5979e-07 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6490 - learning_rate: 8.1000e-04\n",
      "Epoch 331/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9653 - f1_score: 0.9785 - loss: 0.0000e+00 \n",
      "Epoch 331: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9639 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6490 - learning_rate: 8.1000e-04\n",
      "Epoch 332/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9703 - f1_score: 0.9550 - loss: 0.0000e+00 \n",
      "Epoch 332: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9674 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6490 - learning_rate: 8.1000e-04\n",
      "Epoch 333/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9666 - f1_score: 0.9815 - loss: 0.0000e+00 \n",
      "Epoch 333: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9645 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6490 - learning_rate: 8.1000e-04\n",
      "Epoch 334/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9729 - f1_score: 0.9745 - loss: 0.0000e+00 \n",
      "Epoch 334: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9703 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6490 - learning_rate: 8.1000e-04\n",
      "Epoch 335/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9614 - f1_score: 0.9680 - loss: 0.0000e+00 \n",
      "Epoch 335: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9609 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9210 - val_f1_score: 0.9872 - val_loss: 1.6490 - learning_rate: 8.1000e-04\n",
      "Epoch 336/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9605 - f1_score: 0.9615 - loss: 0.0260     \n",
      "Epoch 336: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9599 - f1_score: 0.9706 - loss: 0.0221 - val_accuracy: 0.9193 - val_f1_score: 0.9791 - val_loss: 2.0175 - learning_rate: 8.1000e-04\n",
      "Epoch 337/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9653 - f1_score: 0.9662 - loss: 0.0000e+00 \n",
      "Epoch 337: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9652 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1420 - learning_rate: 8.1000e-04\n",
      "Epoch 338/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9594 - f1_score: 0.9673 - loss: 0.0000e+00 \n",
      "Epoch 338: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9584 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9200 - val_f1_score: 0.9791 - val_loss: 2.1692 - learning_rate: 8.1000e-04\n",
      "Epoch 339/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9448 - f1_score: 0.9833 - loss: 0.0000e+00 \n",
      "Epoch 339: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9484 - f1_score: 0.9875 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1748 - learning_rate: 8.1000e-04\n",
      "Epoch 340/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9666 - f1_score: 0.9760 - loss: 0.0000e+00 \n",
      "Epoch 340: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9640 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1759 - learning_rate: 8.1000e-04\n",
      "Epoch 341/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9553 - f1_score: 0.9707 - loss: 0.0000e+00\n",
      "Epoch 341: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9554 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1760 - learning_rate: 8.1000e-04\n",
      "Epoch 342/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9665 - f1_score: 0.9680 - loss: 0.0000e+00 \n",
      "Epoch 342: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9671 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1761 - learning_rate: 8.1000e-04\n",
      "Epoch 343/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9723 - f1_score: 0.9745 - loss: 3.4708e-09 \n",
      "Epoch 343: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9707 - f1_score: 0.9825 - loss: 4.4582e-09 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1761 - learning_rate: 8.1000e-04\n",
      "Epoch 344/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9478 - f1_score: 0.9782 - loss: 0.0000e+00\n",
      "Epoch 344: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9516 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1761 - learning_rate: 8.1000e-04\n",
      "Epoch 345/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9507 - f1_score: 0.9733 - loss: 0.0000e+00 \n",
      "Epoch 345: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9532 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1761 - learning_rate: 8.1000e-04\n",
      "Epoch 346/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9563 - f1_score: 0.9782 - loss: 0.0000e+00 \n",
      "Epoch 346: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9571 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1761 - learning_rate: 8.1000e-04\n",
      "Epoch 347/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9575 - f1_score: 0.9800 - loss: 0.0000e+00 \n",
      "Epoch 347: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9579 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1761 - learning_rate: 8.1000e-04\n",
      "Epoch 348/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9760 - f1_score: 0.9700 - loss: 0.0000e+00 \n",
      "Epoch 348: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9751 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1761 - learning_rate: 8.1000e-04\n",
      "Epoch 349/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9545 - f1_score: 0.9733 - loss: 0.0000e+00 \n",
      "Epoch 349: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9562 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1761 - learning_rate: 8.1000e-04\n",
      "Epoch 350/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9632 - f1_score: 0.9754 - loss: 0.0000e+00 \n",
      "Epoch 350: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9634 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1761 - learning_rate: 8.1000e-04\n",
      "Epoch 351/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9670 - f1_score: 0.9785 - loss: 0.0000e+00 \n",
      "Epoch 351: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9664 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1761 - learning_rate: 8.1000e-04\n",
      "Epoch 352/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9585 - f1_score: 0.9689 - loss: 0.0000e+00 \n",
      "Epoch 352: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9597 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1761 - learning_rate: 8.1000e-04\n",
      "Epoch 353/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9668 - f1_score: 0.9733 - loss: 0.0000e+00 \n",
      "Epoch 353: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9666 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1761 - learning_rate: 8.1000e-04\n",
      "Epoch 354/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9688 - f1_score: 0.9667 - loss: 0.0000e+00 \n",
      "Epoch 354: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9677 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1761 - learning_rate: 8.1000e-04\n",
      "Epoch 355/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9553 - f1_score: 0.9680 - loss: 0.0000e+00 \n",
      "Epoch 355: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9575 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9197 - val_f1_score: 0.9791 - val_loss: 2.1761 - learning_rate: 8.1000e-04\n",
      "Epoch 356/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9627 - f1_score: 0.9534 - loss: 0.0027     \n",
      "Epoch 356: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9629 - f1_score: 0.9617 - loss: 0.0051 - val_accuracy: 0.9228 - val_f1_score: 0.9791 - val_loss: 2.1693 - learning_rate: 8.1000e-04\n",
      "Epoch 357/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9618 - f1_score: 0.9840 - loss: 0.0000e+00 \n",
      "Epoch 357: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9617 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9203 - val_f1_score: 0.9791 - val_loss: 1.9717 - learning_rate: 8.1000e-04\n",
      "Epoch 358/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9771 - f1_score: 0.9667 - loss: 0.0017     \n",
      "Epoch 358: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9752 - f1_score: 0.9764 - loss: 0.0035 - val_accuracy: 0.9499 - val_f1_score: 0.9872 - val_loss: 1.9801 - learning_rate: 8.1000e-04\n",
      "Epoch 359/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9544 - f1_score: 0.9361 - loss: 0.0051     \n",
      "Epoch 359: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9571 - f1_score: 0.9515 - loss: 0.0079 - val_accuracy: 0.9478 - val_f1_score: 0.9872 - val_loss: 2.0192 - learning_rate: 8.1000e-04\n",
      "Epoch 360/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9672 - f1_score: 0.9692 - loss: 1.1922e-09 \n",
      "Epoch 360: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9655 - f1_score: 0.9745 - loss: 4.9946e-04 - val_accuracy: 0.9294 - val_f1_score: 0.9872 - val_loss: 2.0019 - learning_rate: 8.1000e-04\n",
      "Epoch 361/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9628 - f1_score: 0.9733 - loss: 0.0000e+00 \n",
      "Epoch 361: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9651 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9409 - val_f1_score: 0.9872 - val_loss: 1.9028 - learning_rate: 8.1000e-04\n",
      "Epoch 362/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9778 - f1_score: 0.9636 - loss: 0.0000e+00 \n",
      "Epoch 362: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9778 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9402 - val_f1_score: 0.9755 - val_loss: 1.9795 - learning_rate: 8.1000e-04\n",
      "Epoch 363/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9708 - f1_score: 0.9846 - loss: 2.4151e-09 \n",
      "Epoch 363: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9714 - f1_score: 0.9875 - loss: 3.1389e-09 - val_accuracy: 0.9402 - val_f1_score: 0.9755 - val_loss: 2.0046 - learning_rate: 8.1000e-04\n",
      "Epoch 364/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9621 - f1_score: 0.9689 - loss: 0.0000e+00 \n",
      "Epoch 364: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9670 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9402 - val_f1_score: 0.9755 - val_loss: 2.0092 - learning_rate: 8.1000e-04\n",
      "Epoch 365/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9791 - f1_score: 0.9785 - loss: 0.0000e+00 \n",
      "Epoch 365: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9788 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9402 - val_f1_score: 0.9755 - val_loss: 2.0103 - learning_rate: 8.1000e-04\n",
      "Epoch 366/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9766 - f1_score: 0.9709 - loss: 0.0000e+00 \n",
      "Epoch 366: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9774 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9402 - val_f1_score: 0.9755 - val_loss: 2.0106 - learning_rate: 8.1000e-04\n",
      "Epoch 367/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9708 - f1_score: 0.9517 - loss: 0.0070     \n",
      "Epoch 367: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9713 - f1_score: 0.9690 - loss: 0.0245 - val_accuracy: 0.9367 - val_f1_score: 0.9755 - val_loss: 2.1138 - learning_rate: 8.1000e-04\n",
      "Epoch 368/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9740 - f1_score: 0.9633 - loss: 0.0000e+00 \n",
      "Epoch 368: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9728 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9186 - val_f1_score: 0.9755 - val_loss: 2.1998 - learning_rate: 8.1000e-04\n",
      "Epoch 369/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9675 - f1_score: 0.9644 - loss: 0.0000e+00 \n",
      "Epoch 369: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9663 - f1_score: 0.9800 - loss: 1.3590e-05 - val_accuracy: 0.9151 - val_f1_score: 0.9755 - val_loss: 2.2164 - learning_rate: 8.1000e-04\n",
      "Epoch 370/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9564 - f1_score: 0.9500 - loss: 3.2811e-06 \n",
      "Epoch 370: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9592 - f1_score: 0.9750 - loss: 5.7615e-06 - val_accuracy: 0.9155 - val_f1_score: 0.9755 - val_loss: 2.2176 - learning_rate: 8.1000e-04\n",
      "Epoch 371/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9594 - f1_score: 0.9720 - loss: 5.3414e-07 \n",
      "Epoch 371: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9592 - f1_score: 0.9825 - loss: 5.1679e-07 - val_accuracy: 0.9158 - val_f1_score: 0.9755 - val_loss: 2.2176 - learning_rate: 8.1000e-04\n",
      "Epoch 372/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9815 - f1_score: 0.9569 - loss: 1.3463e-09\n",
      "Epoch 372: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9786 - f1_score: 0.9650 - loss: 1.4861e-09 - val_accuracy: 0.9162 - val_f1_score: 0.9755 - val_loss: 2.2182 - learning_rate: 8.1000e-04\n",
      "Epoch 373/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9605 - f1_score: 0.9891 - loss: 7.4446e-05 \n",
      "Epoch 373: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9608 - f1_score: 0.9925 - loss: 2.5995e-04 - val_accuracy: 0.9190 - val_f1_score: 0.9675 - val_loss: 2.3925 - learning_rate: 8.1000e-04\n",
      "Epoch 374/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9640 - f1_score: 0.9520 - loss: 3.2229e-08 \n",
      "Epoch 374: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9659 - f1_score: 0.9694 - loss: 0.0027 - val_accuracy: 0.9266 - val_f1_score: 0.9675 - val_loss: 2.2441 - learning_rate: 8.1000e-04\n",
      "Epoch 375/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9657 - f1_score: 0.9758 - loss: 0.0188    \n",
      "Epoch 375: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9655 - f1_score: 0.9772 - loss: 0.0352 - val_accuracy: 0.9033 - val_f1_score: 0.9485 - val_loss: 2.7938 - learning_rate: 8.1000e-04\n",
      "Epoch 376/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9471 - f1_score: 0.9538 - loss: 0.2207\n",
      "Epoch 376: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9468 - f1_score: 0.9585 - loss: 0.2174 - val_accuracy: 0.9019 - val_f1_score: 0.9159 - val_loss: 4.5144 - learning_rate: 8.1000e-04\n",
      "Epoch 377/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9434 - f1_score: 0.9779 - loss: 0.1182    \n",
      "Epoch 377: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9422 - f1_score: 0.9798 - loss: 0.1195 - val_accuracy: 0.9026 - val_f1_score: 0.9113 - val_loss: 2.8697 - learning_rate: 8.1000e-04\n",
      "Epoch 378/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9489 - f1_score: 0.9746 - loss: 0.2072    \n",
      "Epoch 378: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9498 - f1_score: 0.9769 - loss: 0.2028 - val_accuracy: 0.9137 - val_f1_score: 0.9355 - val_loss: 2.6509 - learning_rate: 8.1000e-04\n",
      "Epoch 379/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9701 - f1_score: 0.9785 - loss: 0.0586   \n",
      "Epoch 379: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9687 - f1_score: 0.9827 - loss: 0.0692 - val_accuracy: 0.9165 - val_f1_score: 0.9203 - val_loss: 4.0832 - learning_rate: 8.1000e-04\n",
      "Epoch 380/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9585 - f1_score: 0.9637 - loss: 3.2077e-04 \n",
      "Epoch 380: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9560 - f1_score: 0.9764 - loss: 0.0011 - val_accuracy: 0.9085 - val_f1_score: 0.9115 - val_loss: 3.9093 - learning_rate: 8.1000e-04\n",
      "Epoch 381/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9463 - f1_score: 0.9707 - loss: 0.0021    \n",
      "Epoch 381: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9468 - f1_score: 0.9725 - loss: 0.0021 - val_accuracy: 0.9270 - val_f1_score: 0.9252 - val_loss: 3.9440 - learning_rate: 8.1000e-04\n",
      "Epoch 382/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9729 - f1_score: 0.9728 - loss: 0.0028    \n",
      "Epoch 382: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9725 - f1_score: 0.9744 - loss: 0.0032 - val_accuracy: 0.9266 - val_f1_score: 0.9688 - val_loss: 3.3172 - learning_rate: 8.1000e-04\n",
      "Epoch 383/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9755 - f1_score: 0.9800 - loss: 5.1135e-08 \n",
      "Epoch 383: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9718 - f1_score: 0.9875 - loss: 3.8195e-08 - val_accuracy: 0.9315 - val_f1_score: 0.9688 - val_loss: 2.7592 - learning_rate: 8.1000e-04\n",
      "Epoch 384/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9724 - f1_score: 0.9751 - loss: 0.0359    \n",
      "Epoch 384: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9727 - f1_score: 0.9764 - loss: 0.0362 - val_accuracy: 0.9377 - val_f1_score: 0.9775 - val_loss: 1.8978 - learning_rate: 8.1000e-04\n",
      "Epoch 385/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9772 - f1_score: 0.9722 - loss: 0.1836    \n",
      "Epoch 385: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9765 - f1_score: 0.9754 - loss: 0.1734 - val_accuracy: 0.9263 - val_f1_score: 0.9689 - val_loss: 1.9375 - learning_rate: 8.1000e-04\n",
      "Epoch 386/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9647 - f1_score: 0.9726 - loss: 0.0016    \n",
      "Epoch 386: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9649 - f1_score: 0.9742 - loss: 0.0018 - val_accuracy: 0.9283 - val_f1_score: 0.9577 - val_loss: 2.2512 - learning_rate: 8.1000e-04\n",
      "Epoch 387/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9678 - f1_score: 0.9600 - loss: 0.0000e+00\n",
      "Epoch 387: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9653 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9273 - val_f1_score: 0.9689 - val_loss: 2.1148 - learning_rate: 8.1000e-04\n",
      "Epoch 388/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9533 - f1_score: 0.9600 - loss: 0.0000e+00 \n",
      "Epoch 388: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9570 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9263 - val_f1_score: 0.9689 - val_loss: 2.0916 - learning_rate: 8.1000e-04\n",
      "Epoch 389/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9638 - f1_score: 0.9815 - loss: 0.0000e+00\n",
      "Epoch 389: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9636 - f1_score: 0.9850 - loss: 3.2394e-11 - val_accuracy: 0.9259 - val_f1_score: 0.9689 - val_loss: 2.0871 - learning_rate: 8.1000e-04\n",
      "Epoch 390/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9599 - f1_score: 0.9578 - loss: 0.0301     \n",
      "Epoch 390: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9598 - f1_score: 0.9653 - loss: 0.0301 - val_accuracy: 0.9221 - val_f1_score: 0.9446 - val_loss: 4.2477 - learning_rate: 8.1000e-04\n",
      "Epoch 391/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9635 - f1_score: 0.9635 - loss: 0.0638 \n",
      "Epoch 391: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9645 - f1_score: 0.9694 - loss: 0.0640 - val_accuracy: 0.9367 - val_f1_score: 0.9630 - val_loss: 3.6832 - learning_rate: 8.1000e-04\n",
      "Epoch 392/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9758 - f1_score: 0.9576 - loss: 0.0130    \n",
      "Epoch 392: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9759 - f1_score: 0.9599 - loss: 0.0151 - val_accuracy: 0.9315 - val_f1_score: 0.9612 - val_loss: 4.3151 - learning_rate: 8.1000e-04\n",
      "Epoch 393/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9779 - f1_score: 0.9691 - loss: 0.1401     \n",
      "Epoch 393: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9777 - f1_score: 0.9780 - loss: 0.1140 - val_accuracy: 0.9409 - val_f1_score: 0.9620 - val_loss: 4.6285 - learning_rate: 8.1000e-04\n",
      "Epoch 394/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9591 - f1_score: 0.9640 - loss: 0.0000e+00 \n",
      "Epoch 394: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9585 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9200 - val_f1_score: 0.9460 - val_loss: 5.4080 - learning_rate: 8.1000e-04\n",
      "Epoch 395/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9601 - f1_score: 0.9501 - loss: 0.0031     \n",
      "Epoch 395: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9615 - f1_score: 0.9620 - loss: 0.0028 - val_accuracy: 0.9544 - val_f1_score: 0.9620 - val_loss: 4.7753 - learning_rate: 8.1000e-04\n",
      "Epoch 396/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9719 - f1_score: 0.9908 - loss: 0.0000e+00 \n",
      "Epoch 396: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9729 - f1_score: 0.9925 - loss: 0.0000e+00 - val_accuracy: 0.9544 - val_f1_score: 0.9620 - val_loss: 4.7076 - learning_rate: 8.1000e-04\n",
      "Epoch 397/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9777 - f1_score: 0.9800 - loss: 0.0000e+00 \n",
      "Epoch 397: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9779 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9537 - val_f1_score: 0.9620 - val_loss: 4.6922 - learning_rate: 8.1000e-04\n",
      "Epoch 398/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9777 - f1_score: 0.9629 - loss: 0.0000e+00 \n",
      "Epoch 398: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9775 - f1_score: 0.9675 - loss: 0.0000e+00 - val_accuracy: 0.9537 - val_f1_score: 0.9620 - val_loss: 4.6891 - learning_rate: 8.1000e-04\n",
      "Epoch 399/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9901 - f1_score: 0.9782 - loss: 0.0000e+00 \n",
      "Epoch 399: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\n",
      "Epoch 399: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9888 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9537 - val_f1_score: 0.9620 - val_loss: 4.6888 - learning_rate: 8.1000e-04\n",
      "Epoch 400/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9811 - f1_score: 0.9709 - loss: 0.0000e+00 \n",
      "Epoch 400: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9807 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9537 - val_f1_score: 0.9620 - val_loss: 4.6885 - learning_rate: 7.2900e-04\n",
      "Epoch 401/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9703 - f1_score: 0.9720 - loss: 1.8264e-06 \n",
      "Epoch 401: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9707 - f1_score: 0.9825 - loss: 1.9578e-06 - val_accuracy: 0.9537 - val_f1_score: 0.9620 - val_loss: 4.6891 - learning_rate: 7.2900e-04\n",
      "Epoch 402/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9777 - f1_score: 0.9813 - loss: 1.2935e-08 \n",
      "Epoch 402: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9778 - f1_score: 0.9825 - loss: 1.5997e-08 - val_accuracy: 0.9537 - val_f1_score: 0.9620 - val_loss: 4.6891 - learning_rate: 7.2900e-04\n",
      "Epoch 403/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9812 - f1_score: 0.9692 - loss: 0.0000e+00 \n",
      "Epoch 403: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9812 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9537 - val_f1_score: 0.9620 - val_loss: 4.6878 - learning_rate: 7.2900e-04\n",
      "Epoch 404/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9778 - f1_score: 0.9686 - loss: 0.0000e+00 \n",
      "Epoch 404: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9771 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9537 - val_f1_score: 0.9620 - val_loss: 4.6879 - learning_rate: 7.2900e-04\n",
      "Epoch 405/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9791 - f1_score: 0.9633 - loss: 0.0000e+00 \n",
      "Epoch 405: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9785 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9537 - val_f1_score: 0.9620 - val_loss: 4.6878 - learning_rate: 7.2900e-04\n",
      "Epoch 406/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - f1_score: 0.9560 - loss: 0.0000e+00 \n",
      "Epoch 406: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9799 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9537 - val_f1_score: 0.9620 - val_loss: 4.6878 - learning_rate: 7.2900e-04\n",
      "Epoch 407/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9818 - f1_score: 0.9567 - loss: 0.0000e+00 \n",
      "Epoch 407: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9800 - f1_score: 0.9668 - loss: 0.0065 - val_accuracy: 0.9558 - val_f1_score: 0.9791 - val_loss: 2.4448 - learning_rate: 7.2900e-04\n",
      "Epoch 408/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9781 - f1_score: 0.9491 - loss: 0.0000e+00 \n",
      "Epoch 408: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9774 - f1_score: 0.9650 - loss: 1.6197e-10 - val_accuracy: 0.9603 - val_f1_score: 0.9684 - val_loss: 3.6151 - learning_rate: 7.2900e-04\n",
      "Epoch 409/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9709 - f1_score: 0.9815 - loss: 0.0028     \n",
      "Epoch 409: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9711 - f1_score: 0.9850 - loss: 0.0025 - val_accuracy: 0.9590 - val_f1_score: 0.9791 - val_loss: 2.5022 - learning_rate: 7.2900e-04\n",
      "Epoch 410/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9715 - f1_score: 0.9733 - loss: 0.0000e+00 \n",
      "Epoch 410: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9736 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4191 - learning_rate: 7.2900e-04\n",
      "Epoch 411/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9720 - f1_score: 0.9680 - loss: 7.4816e-11\n",
      "Epoch 411: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9723 - f1_score: 0.9700 - loss: 8.6337e-11 - val_accuracy: 0.9569 - val_f1_score: 0.9791 - val_loss: 2.4019 - learning_rate: 7.2900e-04\n",
      "Epoch 412/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9801 - f1_score: 0.9745 - loss: 0.0000e+00 \n",
      "Epoch 412: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9807 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9569 - val_f1_score: 0.9791 - val_loss: 2.3988 - learning_rate: 7.2900e-04\n",
      "Epoch 413/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9742 - f1_score: 0.9745 - loss: 2.6469e-05 \n",
      "Epoch 413: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9723 - f1_score: 0.9825 - loss: 2.1538e-05 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4005 - learning_rate: 7.2900e-04\n",
      "Epoch 414/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9841 - f1_score: 0.9707 - loss: 1.9479e-10\n",
      "Epoch 414: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9839 - f1_score: 0.9725 - loss: 2.1501e-10 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4012 - learning_rate: 7.2900e-04\n",
      "Epoch 415/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9660 - f1_score: 0.9600 - loss: 0.0000e+00 \n",
      "Epoch 415: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9705 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4013 - learning_rate: 7.2900e-04\n",
      "Epoch 416/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9587 - f1_score: 0.9511 - loss: 0.0000e+00 \n",
      "Epoch 416: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9640 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4013 - learning_rate: 7.2900e-04\n",
      "Epoch 417/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9659 - f1_score: 0.9720 - loss: 2.9806e-06 \n",
      "Epoch 417: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9670 - f1_score: 0.9825 - loss: 2.8801e-06 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4016 - learning_rate: 7.2900e-04\n",
      "Epoch 418/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9779 - f1_score: 0.9600 - loss: 0.0000e+00 \n",
      "Epoch 418: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9771 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4016 - learning_rate: 7.2900e-04\n",
      "Epoch 419/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9838 - f1_score: 0.9709 - loss: 2.5089e-09 \n",
      "Epoch 419: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9807 - f1_score: 0.9800 - loss: 2.8473e-09 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4016 - learning_rate: 7.2900e-04\n",
      "Epoch 420/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - f1_score: 0.9785 - loss: 0.0000e+00 \n",
      "Epoch 420: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9702 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4016 - learning_rate: 7.2900e-04\n",
      "Epoch 421/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9657 - f1_score: 0.9550 - loss: 0.0000e+00 \n",
      "Epoch 421: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9730 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4016 - learning_rate: 7.2900e-04\n",
      "Epoch 422/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9754 - f1_score: 0.9657 - loss: 0.0000e+00\n",
      "Epoch 422: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9761 - f1_score: 0.9700 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4016 - learning_rate: 7.2900e-04\n",
      "Epoch 423/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9793 - f1_score: 0.9631 - loss: 0.0000e+00\n",
      "Epoch 423: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9784 - f1_score: 0.9700 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4016 - learning_rate: 7.2900e-04\n",
      "Epoch 424/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9784 - f1_score: 0.9815 - loss: 0.0000e+00\n",
      "Epoch 424: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9792 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4016 - learning_rate: 7.2900e-04\n",
      "Epoch 425/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9697 - f1_score: 0.9771 - loss: 0.0000e+00\n",
      "Epoch 425: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9707 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4016 - learning_rate: 7.2900e-04\n",
      "Epoch 426/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9794 - f1_score: 0.9785 - loss: 0.0000e+00\n",
      "Epoch 426: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9792 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4016 - learning_rate: 7.2900e-04\n",
      "Epoch 427/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9800 - f1_score: 0.9771 - loss: 0.0000e+00\n",
      "Epoch 427: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9800 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4016 - learning_rate: 7.2900e-04\n",
      "Epoch 428/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9803 - f1_score: 0.9813 - loss: 0.0000e+00\n",
      "Epoch 428: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9803 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4016 - learning_rate: 7.2900e-04\n",
      "Epoch 429/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9701 - f1_score: 0.9813 - loss: 2.1635e-10 \n",
      "Epoch 429: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9703 - f1_score: 0.9825 - loss: 2.1902e-10 - val_accuracy: 0.9583 - val_f1_score: 0.9791 - val_loss: 2.4016 - learning_rate: 7.2900e-04\n",
      "Epoch 430/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9809 - f1_score: 0.9749 - loss: 0.0319 \n",
      "Epoch 430: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9812 - f1_score: 0.9777 - loss: 0.0291 - val_accuracy: 0.9690 - val_f1_score: 0.9791 - val_loss: 2.3762 - learning_rate: 7.2900e-04\n",
      "Epoch 431/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9904 - f1_score: 0.9680 - loss: 0.0000e+00 \n",
      "Epoch 431: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9901 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9791 - val_loss: 2.3578 - learning_rate: 7.2900e-04\n",
      "Epoch 432/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9954 - f1_score: 0.9700 - loss: 0.0000e+00 \n",
      "Epoch 432: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9947 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9791 - val_loss: 2.3532 - learning_rate: 7.2900e-04\n",
      "Epoch 433/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - f1_score: 0.9800 - loss: 9.4563e-09 \n",
      "Epoch 433: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9885 - f1_score: 0.9850 - loss: 8.3640e-09 - val_accuracy: 0.9680 - val_f1_score: 0.9791 - val_loss: 2.3520 - learning_rate: 7.2900e-04\n",
      "Epoch 434/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9859 - f1_score: 0.9700 - loss: 0.0000e+00 \n",
      "Epoch 434: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9853 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9791 - val_loss: 2.3519 - learning_rate: 7.2900e-04\n",
      "Epoch 435/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9876 - f1_score: 0.9733 - loss: 0.0000e+00 \n",
      "Epoch 435: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9880 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9791 - val_loss: 2.3518 - learning_rate: 7.2900e-04\n",
      "Epoch 436/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9951 - f1_score: 0.9600 - loss: 0.0000e+00 \n",
      "Epoch 436: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9949 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9791 - val_loss: 2.3519 - learning_rate: 7.2900e-04\n",
      "Epoch 437/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9893 - f1_score: 0.9787 - loss: 0.0000e+00 \n",
      "Epoch 437: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9892 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9791 - val_loss: 2.3519 - learning_rate: 7.2900e-04\n",
      "Epoch 438/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9741 - f1_score: 0.9754 - loss: 0.0000e+00 \n",
      "Epoch 438: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9760 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9791 - val_loss: 2.3519 - learning_rate: 7.2900e-04\n",
      "Epoch 439/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9926 - f1_score: 0.9800 - loss: 4.1654e-05  \n",
      "Epoch 439: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9927 - f1_score: 0.9850 - loss: 4.2194e-05 - val_accuracy: 0.9680 - val_f1_score: 0.9791 - val_loss: 2.3458 - learning_rate: 7.2900e-04\n",
      "Epoch 440/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9858 - f1_score: 0.9743 - loss: 0.0000e+00\n",
      "Epoch 440: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9860 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9791 - val_loss: 2.3430 - learning_rate: 7.2900e-04\n",
      "Epoch 441/1000\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9987 - f1_score: 0.7200 - loss: 0.0000e+00\n",
      "Epoch 441: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9903 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9683 - val_f1_score: 0.9791 - val_loss: 2.3429 - learning_rate: 7.2900e-04\n",
      "Epoch 442/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9898 - f1_score: 0.9733 - loss: 3.5016e-11 \n",
      "Epoch 442: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9897 - f1_score: 0.9750 - loss: 4.9025e-11 - val_accuracy: 0.9683 - val_f1_score: 0.9791 - val_loss: 2.3429 - learning_rate: 7.2900e-04\n",
      "Epoch 443/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9928 - f1_score: 0.9633 - loss: 0.0000e+00 \n",
      "Epoch 443: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9915 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9683 - val_f1_score: 0.9791 - val_loss: 2.3428 - learning_rate: 7.2900e-04\n",
      "Epoch 444/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9786 - f1_score: 0.9813 - loss: 0.0118     \n",
      "Epoch 444: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9795 - f1_score: 0.9834 - loss: 0.0125 - val_accuracy: 0.9694 - val_f1_score: 0.9791 - val_loss: 2.3262 - learning_rate: 7.2900e-04\n",
      "Epoch 445/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9923 - f1_score: 0.9600 - loss: 0.0000e+00 \n",
      "Epoch 445: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9910 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9677 - val_f1_score: 0.9791 - val_loss: 2.2791 - learning_rate: 7.2900e-04\n",
      "Epoch 446/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9888 - f1_score: 0.9662 - loss: 2.0923e-10 \n",
      "Epoch 446: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9883 - f1_score: 0.9725 - loss: 2.1902e-10 - val_accuracy: 0.9670 - val_f1_score: 0.9791 - val_loss: 2.2666 - learning_rate: 7.2900e-04\n",
      "Epoch 447/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9859 - f1_score: 0.9778 - loss: 0.0000e+00 \n",
      "Epoch 447: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9861 - f1_score: 0.9875 - loss: 0.0000e+00 - val_accuracy: 0.9670 - val_f1_score: 0.9791 - val_loss: 2.2644 - learning_rate: 7.2900e-04\n",
      "Epoch 448/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9756 - f1_score: 0.9640 - loss: 0.0000e+00 \n",
      "Epoch 448: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9781 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9670 - val_f1_score: 0.9791 - val_loss: 2.2639 - learning_rate: 7.2900e-04\n",
      "Epoch 449/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9902 - f1_score: 0.9760 - loss: 9.6299e-07 \n",
      "Epoch 449: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9893 - f1_score: 0.9850 - loss: 1.0820e-06 - val_accuracy: 0.9670 - val_f1_score: 0.9791 - val_loss: 2.2651 - learning_rate: 7.2900e-04\n",
      "Epoch 450/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9796 - f1_score: 0.9449 - loss: 0.0058     \n",
      "Epoch 450: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9810 - f1_score: 0.9614 - loss: 0.0118 - val_accuracy: 0.9670 - val_f1_score: 0.9791 - val_loss: 2.3338 - learning_rate: 7.2900e-04\n",
      "Epoch 451/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9840 - f1_score: 0.9743 - loss: 0.0000e+00\n",
      "Epoch 451: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9839 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9659 - val_f1_score: 0.9731 - val_loss: 2.3915 - learning_rate: 7.2900e-04\n",
      "Epoch 452/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9818 - f1_score: 0.9731 - loss: 0.0359  \n",
      "Epoch 452: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9822 - f1_score: 0.9762 - loss: 0.0396 - val_accuracy: 0.9649 - val_f1_score: 0.9791 - val_loss: 2.3029 - learning_rate: 7.2900e-04\n",
      "Epoch 453/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9870 - f1_score: 0.9716 - loss: 0.0202   \n",
      "Epoch 453: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9860 - f1_score: 0.9781 - loss: 0.0205 - val_accuracy: 0.9659 - val_f1_score: 0.9791 - val_loss: 3.7305 - learning_rate: 7.2900e-04\n",
      "Epoch 454/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9834 - f1_score: 0.9625 - loss: 0.0249    \n",
      "Epoch 454: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9834 - f1_score: 0.9691 - loss: 0.0373 - val_accuracy: 0.9708 - val_f1_score: 0.9791 - val_loss: 3.3279 - learning_rate: 7.2900e-04\n",
      "Epoch 455/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9809 - f1_score: 0.9729 - loss: 0.0593    \n",
      "Epoch 455: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9812 - f1_score: 0.9743 - loss: 0.0591 - val_accuracy: 0.9677 - val_f1_score: 0.9791 - val_loss: 1.9635 - learning_rate: 7.2900e-04\n",
      "Epoch 456/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9857 - f1_score: 0.9745 - loss: 9.9040e-06\n",
      "Epoch 456: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9871 - f1_score: 0.9825 - loss: 1.5157e-05 - val_accuracy: 0.9677 - val_f1_score: 0.9791 - val_loss: 1.9039 - learning_rate: 7.2900e-04\n",
      "Epoch 457/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9925 - f1_score: 0.9733 - loss: 0.0000e+00\n",
      "Epoch 457: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9923 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9791 - val_loss: 1.8900 - learning_rate: 7.2900e-04\n",
      "Epoch 458/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9863 - f1_score: 0.9667 - loss: 8.7418e-04\n",
      "Epoch 458: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9856 - f1_score: 0.9750 - loss: 8.4044e-04 - val_accuracy: 0.9673 - val_f1_score: 0.9791 - val_loss: 2.4222 - learning_rate: 7.2900e-04\n",
      "Epoch 459/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9889 - f1_score: 0.9480 - loss: 0.0000e+00\n",
      "Epoch 459: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9890 - f1_score: 0.9675 - loss: 0.0000e+00 - val_accuracy: 0.9649 - val_f1_score: 0.9791 - val_loss: 2.6219 - learning_rate: 7.2900e-04\n",
      "Epoch 460/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9725 - f1_score: 0.9760 - loss: 0.0000e+00\n",
      "Epoch 460: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9758 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6630 - learning_rate: 7.2900e-04\n",
      "Epoch 461/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9883 - f1_score: 0.9508 - loss: 0.0000e+00\n",
      "Epoch 461: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9867 - f1_score: 0.9600 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6713 - learning_rate: 7.2900e-04\n",
      "Epoch 462/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9783 - f1_score: 0.9700 - loss: 0.0000e+00\n",
      "Epoch 462: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9790 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6732 - learning_rate: 7.2900e-04\n",
      "Epoch 463/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9768 - f1_score: 0.9707 - loss: 1.0945e-08\n",
      "Epoch 463: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9769 - f1_score: 0.9725 - loss: 1.1427e-08 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 464/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9896 - f1_score: 0.9627 - loss: 0.0000e+00\n",
      "Epoch 464: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9895 - f1_score: 0.9650 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 465/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9878 - f1_score: 0.9782 - loss: 0.0000e+00 \n",
      "Epoch 465: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9854 - f1_score: 0.9850 - loss: 8.6337e-11 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 466/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9844 - f1_score: 0.9709 - loss: 0.0000e+00\n",
      "Epoch 466: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9839 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 467/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9888 - f1_score: 0.9644 - loss: 0.0000e+00 \n",
      "Epoch 467: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9882 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 468/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9779 - f1_score: 0.9723 - loss: 0.0000e+00\n",
      "Epoch 468: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9777 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 469/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9898 - f1_score: 0.9782 - loss: 0.0000e+00 \n",
      "Epoch 469: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9881 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 470/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9726 - f1_score: 0.9714 - loss: 2.6782e-08\n",
      "Epoch 470: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9737 - f1_score: 0.9750 - loss: 2.7904e-08 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 471/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9773 - f1_score: 0.9689 - loss: 0.0000e+00 \n",
      "Epoch 471: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9803 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 472/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9768 - f1_score: 0.9800 - loss: 1.4582e-07\n",
      "Epoch 472: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9770 - f1_score: 0.9825 - loss: 1.5455e-07 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 473/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9827 - f1_score: 0.9723 - loss: 0.0000e+00 \n",
      "Epoch 473: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9823 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6735 - learning_rate: 7.2900e-04\n",
      "Epoch 474/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9766 - f1_score: 0.9767 - loss: 0.0000e+00\n",
      "Epoch 474: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9781 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 475/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9739 - f1_score: 0.9760 - loss: 0.0000e+00 \n",
      "Epoch 475: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9753 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 476/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9892 - f1_score: 0.9754 - loss: 0.0000e+00 \n",
      "Epoch 476: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9886 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 477/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9799 - f1_score: 0.9733 - loss: 0.0000e+00\n",
      "Epoch 477: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9798 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 478/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9824 - f1_score: 0.9829 - loss: 0.0000e+00\n",
      "Epoch 478: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9819 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 479/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9810 - f1_score: 0.9743 - loss: 0.0000e+00\n",
      "Epoch 479: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9810 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 480/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9811 - f1_score: 0.9754 - loss: 0.0000e+00\n",
      "Epoch 480: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9803 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 481/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9784 - f1_score: 0.9857 - loss: 0.0000e+00\n",
      "Epoch 481: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9791 - f1_score: 0.9875 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 482/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9712 - f1_score: 0.9743 - loss: 0.0000e+00\n",
      "Epoch 482: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9720 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 483/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9776 - f1_score: 0.9743 - loss: 0.0000e+00\n",
      "Epoch 483: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9781 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 484/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9791 - f1_score: 0.9709 - loss: 0.0000e+00\n",
      "Epoch 484: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9797 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 485/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9865 - f1_score: 0.9629 - loss: 0.0000e+00\n",
      "Epoch 485: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9863 - f1_score: 0.9675 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 486/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9767 - f1_score: 0.9733 - loss: 0.0000e+00\n",
      "Epoch 486: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9770 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 487/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9816 - f1_score: 0.9743 - loss: 0.0000e+00\n",
      "Epoch 487: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9821 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 488/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9765 - f1_score: 0.9815 - loss: 0.0000e+00 \n",
      "Epoch 488: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9771 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6734 - learning_rate: 7.2900e-04\n",
      "Epoch 489/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9930 - f1_score: 0.9300 - loss: 0.0000e+00 \n",
      "Epoch 489: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9903 - f1_score: 0.9650 - loss: 1.2953e-07 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6735 - learning_rate: 7.2900e-04\n",
      "Epoch 490/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9766 - f1_score: 0.9754 - loss: 0.0000e+00 \n",
      "Epoch 490: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9767 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6736 - learning_rate: 7.2900e-04\n",
      "Epoch 491/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9771 - f1_score: 0.9800 - loss: 0.0000e+00 \n",
      "Epoch 491: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9774 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6735 - learning_rate: 7.2900e-04\n",
      "Epoch 492/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9827 - f1_score: 0.9733 - loss: 0.0000e+00 \n",
      "Epoch 492: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9827 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9791 - val_loss: 2.6735 - learning_rate: 7.2900e-04\n",
      "Epoch 493/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9832 - f1_score: 0.9769 - loss: 0.0166     \n",
      "Epoch 493: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9828 - f1_score: 0.9834 - loss: 0.0142 - val_accuracy: 0.9666 - val_f1_score: 0.9791 - val_loss: 2.8908 - learning_rate: 7.2900e-04\n",
      "Epoch 494/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9808 - f1_score: 0.9720 - loss: 0.0000e+00 \n",
      "Epoch 494: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9805 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9677 - val_f1_score: 0.9731 - val_loss: 2.9582 - learning_rate: 7.2900e-04\n",
      "Epoch 495/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9904 - f1_score: 0.9782 - loss: 0.0000e+00 \n",
      "Epoch 495: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9885 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9731 - val_loss: 2.9776 - learning_rate: 7.2900e-04\n",
      "Epoch 496/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9852 - f1_score: 0.9673 - loss: 0.0000e+00 \n",
      "Epoch 496: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9844 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9731 - val_loss: 2.9828 - learning_rate: 7.2900e-04\n",
      "Epoch 497/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9858 - f1_score: 0.9733 - loss: 0.0000e+00 \n",
      "Epoch 497: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9856 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9731 - val_loss: 2.9834 - learning_rate: 7.2900e-04\n",
      "Epoch 498/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9856 - f1_score: 0.9771 - loss: 0.0000e+00 \n",
      "Epoch 498: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9854 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9731 - val_loss: 2.9836 - learning_rate: 7.2900e-04\n",
      "Epoch 499/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9829 - f1_score: 0.9867 - loss: 0.0000e+00 \n",
      "Epoch 499: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\n",
      "Epoch 499: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9826 - f1_score: 0.9900 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9731 - val_loss: 2.9839 - learning_rate: 7.2900e-04\n",
      "Epoch 500/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9910 - f1_score: 0.9754 - loss: 0.0000e+00 \n",
      "Epoch 500: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9895 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9731 - val_loss: 2.9839 - learning_rate: 6.5610e-04\n",
      "Epoch 501/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9843 - f1_score: 0.9760 - loss: 0.0000e+00 \n",
      "Epoch 501: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9841 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9731 - val_loss: 2.9839 - learning_rate: 6.5610e-04\n",
      "Epoch 502/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9874 - f1_score: 0.9846 - loss: 0.0000e+00 \n",
      "Epoch 502: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9872 - f1_score: 0.9875 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9731 - val_loss: 2.9839 - learning_rate: 6.5610e-04\n",
      "Epoch 503/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9838 - f1_score: 0.9709 - loss: 0.0000e+00 \n",
      "Epoch 503: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9837 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9680 - val_f1_score: 0.9731 - val_loss: 2.9839 - learning_rate: 6.5610e-04\n",
      "Epoch 504/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9804 - f1_score: 0.9700 - loss: 7.8856e-05 \n",
      "Epoch 504: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9815 - f1_score: 0.9775 - loss: 8.5171e-05 - val_accuracy: 0.9680 - val_f1_score: 0.9731 - val_loss: 2.9670 - learning_rate: 6.5610e-04\n",
      "Epoch 505/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9788 - f1_score: 0.9628 - loss: 0.0131     \n",
      "Epoch 505: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9808 - f1_score: 0.9733 - loss: 0.0277 - val_accuracy: 0.9694 - val_f1_score: 0.9872 - val_loss: 2.8062 - learning_rate: 6.5610e-04\n",
      "Epoch 506/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9867 - f1_score: 0.9564 - loss: 4.0909e-09 \n",
      "Epoch 506: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9870 - f1_score: 0.9695 - loss: 0.0045 - val_accuracy: 0.9666 - val_f1_score: 0.9731 - val_loss: 3.0532 - learning_rate: 6.5610e-04\n",
      "Epoch 507/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9836 - f1_score: 0.9730 - loss: 0.1847    \n",
      "Epoch 507: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9834 - f1_score: 0.9746 - loss: 0.1829 - val_accuracy: 0.9520 - val_f1_score: 0.9628 - val_loss: 5.5788 - learning_rate: 6.5610e-04\n",
      "Epoch 508/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9729 - f1_score: 0.9549 - loss: 0.1980 \n",
      "Epoch 508: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9769 - f1_score: 0.9699 - loss: 0.1617 - val_accuracy: 0.9621 - val_f1_score: 0.9740 - val_loss: 3.6497 - learning_rate: 6.5610e-04\n",
      "Epoch 509/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9795 - f1_score: 0.9550 - loss: 1.9613e-08 \n",
      "Epoch 509: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9779 - f1_score: 0.9775 - loss: 3.1895e-08 - val_accuracy: 0.9642 - val_f1_score: 0.9740 - val_loss: 3.2076 - learning_rate: 6.5610e-04\n",
      "Epoch 510/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9837 - f1_score: 0.9783 - loss: 0.0049     \n",
      "Epoch 510: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9848 - f1_score: 0.9857 - loss: 0.0053 - val_accuracy: 0.9656 - val_f1_score: 0.9513 - val_loss: 3.3245 - learning_rate: 6.5610e-04\n",
      "Epoch 511/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9844 - f1_score: 0.9800 - loss: 4.9426e-08 \n",
      "Epoch 511: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9845 - f1_score: 0.9825 - loss: 4.8398e-08 - val_accuracy: 0.9673 - val_f1_score: 0.9513 - val_loss: 3.8096 - learning_rate: 6.5610e-04\n",
      "Epoch 512/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9784 - f1_score: 0.9774 - loss: 0.1589     \n",
      "Epoch 512: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9801 - f1_score: 0.9825 - loss: 0.1355 - val_accuracy: 0.9680 - val_f1_score: 0.9652 - val_loss: 3.3619 - learning_rate: 6.5610e-04\n",
      "Epoch 513/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9839 - f1_score: 0.9662 - loss: 0.0000e+00 \n",
      "Epoch 513: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9841 - f1_score: 0.9721 - loss: 0.0330 - val_accuracy: 0.9683 - val_f1_score: 0.9652 - val_loss: 3.4052 - learning_rate: 6.5610e-04\n",
      "Epoch 514/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9900 - f1_score: 0.9662 - loss: 0.0000e+00 \n",
      "Epoch 514: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9899 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9638 - val_f1_score: 0.9659 - val_loss: 3.4949 - learning_rate: 6.5610e-04\n",
      "Epoch 515/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9862 - f1_score: 0.9495 - loss: 0.0283     \n",
      "Epoch 515: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9866 - f1_score: 0.9616 - loss: 0.0261 - val_accuracy: 0.9610 - val_f1_score: 0.9675 - val_loss: 3.4315 - learning_rate: 6.5610e-04\n",
      "Epoch 516/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9806 - f1_score: 0.9781 - loss: 0.1261     \n",
      "Epoch 516: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9810 - f1_score: 0.9805 - loss: 0.1295 - val_accuracy: 0.9628 - val_f1_score: 0.9603 - val_loss: 3.9006 - learning_rate: 6.5610e-04\n",
      "Epoch 517/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9831 - f1_score: 0.9733 - loss: 0.0000e+00 \n",
      "Epoch 517: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9834 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9614 - val_f1_score: 0.9564 - val_loss: 4.0335 - learning_rate: 6.5610e-04\n",
      "Epoch 518/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9832 - f1_score: 0.9778 - loss: 0.0000e+00 \n",
      "Epoch 518: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9824 - f1_score: 0.9863 - loss: 0.0258 - val_accuracy: 0.9628 - val_f1_score: 0.9603 - val_loss: 4.2794 - learning_rate: 6.5610e-04\n",
      "Epoch 519/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9799 - f1_score: 0.9680 - loss: 0.0000e+00 \n",
      "Epoch 519: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9804 - f1_score: 0.9791 - loss: 0.0505 - val_accuracy: 0.9593 - val_f1_score: 0.9603 - val_loss: 4.5399 - learning_rate: 6.5610e-04\n",
      "Epoch 520/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9883 - f1_score: 0.9667 - loss: 3.3631e-09 \n",
      "Epoch 520: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9855 - f1_score: 0.9743 - loss: 0.0605 - val_accuracy: 0.9628 - val_f1_score: 0.9547 - val_loss: 4.6507 - learning_rate: 6.5610e-04\n",
      "Epoch 521/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9804 - f1_score: 0.9567 - loss: 0.0000e+00 \n",
      "Epoch 521: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9796 - f1_score: 0.9675 - loss: 0.0000e+00 - val_accuracy: 0.9628 - val_f1_score: 0.9459 - val_loss: 4.6457 - learning_rate: 6.5610e-04\n",
      "Epoch 522/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9658 - f1_score: 0.9522 - loss: 0.0351     \n",
      "Epoch 522: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9696 - f1_score: 0.9664 - loss: 0.0710 - val_accuracy: 0.9631 - val_f1_score: 0.9459 - val_loss: 4.4117 - learning_rate: 6.5610e-04\n",
      "Epoch 523/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9846 - f1_score: 0.9600 - loss: 3.1430e-10 \n",
      "Epoch 523: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9835 - f1_score: 0.9675 - loss: 3.0439e-10 - val_accuracy: 0.9590 - val_f1_score: 0.9516 - val_loss: 4.2647 - learning_rate: 6.5610e-04\n",
      "Epoch 524/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9861 - f1_score: 0.9720 - loss: 1.3773e-09 \n",
      "Epoch 524: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9829 - f1_score: 0.9814 - loss: 0.0108 - val_accuracy: 0.9590 - val_f1_score: 0.9516 - val_loss: 4.2659 - learning_rate: 6.5610e-04\n",
      "Epoch 525/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9747 - f1_score: 0.9753 - loss: 0.0389    \n",
      "Epoch 525: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9748 - f1_score: 0.9767 - loss: 0.0449 - val_accuracy: 0.9649 - val_f1_score: 0.9654 - val_loss: 3.3046 - learning_rate: 6.5610e-04\n",
      "Epoch 526/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9891 - f1_score: 0.9627 - loss: 0.0033     \n",
      "Epoch 526: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9859 - f1_score: 0.9737 - loss: 0.0043 - val_accuracy: 0.9649 - val_f1_score: 0.9791 - val_loss: 2.6504 - learning_rate: 6.5610e-04\n",
      "Epoch 527/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9740 - f1_score: 0.9723 - loss: 2.1196e-09 \n",
      "Epoch 527: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9728 - f1_score: 0.9775 - loss: 2.3104e-09 - val_accuracy: 0.9635 - val_f1_score: 0.9791 - val_loss: 2.4627 - learning_rate: 6.5610e-04\n",
      "Epoch 528/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9769 - f1_score: 0.9681 - loss: 0.0758     \n",
      "Epoch 528: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9769 - f1_score: 0.9772 - loss: 0.0727 - val_accuracy: 0.9652 - val_f1_score: 0.9835 - val_loss: 2.2074 - learning_rate: 6.5610e-04\n",
      "Epoch 529/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9728 - f1_score: 0.9595 - loss: 0.0078     \n",
      "Epoch 529: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9740 - f1_score: 0.9715 - loss: 0.0158 - val_accuracy: 0.9670 - val_f1_score: 0.9835 - val_loss: 2.1748 - learning_rate: 6.5610e-04\n",
      "Epoch 530/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9743 - f1_score: 0.9760 - loss: 0.0000e+00\n",
      "Epoch 530: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9747 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9670 - val_f1_score: 0.9835 - val_loss: 2.1538 - learning_rate: 6.5610e-04\n",
      "Epoch 531/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9711 - f1_score: 0.9633 - loss: 0.0000e+00 \n",
      "Epoch 531: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9738 - f1_score: 0.9720 - loss: 0.0047 - val_accuracy: 0.9718 - val_f1_score: 0.9835 - val_loss: 2.6689 - learning_rate: 6.5610e-04\n",
      "Epoch 532/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9745 - f1_score: 0.9709 - loss: 1.8722e-05 \n",
      "Epoch 532: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9750 - f1_score: 0.9800 - loss: 6.5374e-05 - val_accuracy: 0.9715 - val_f1_score: 0.9835 - val_loss: 4.0026 - learning_rate: 6.5610e-04\n",
      "Epoch 533/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9766 - f1_score: 0.9662 - loss: 0.0266     \n",
      "Epoch 533: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9784 - f1_score: 0.9778 - loss: 0.0326 - val_accuracy: 0.9642 - val_f1_score: 0.9582 - val_loss: 4.4923 - learning_rate: 6.5610e-04\n",
      "Epoch 534/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9821 - f1_score: 0.9588 - loss: 0.0107     \n",
      "Epoch 534: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9814 - f1_score: 0.9678 - loss: 0.0373 - val_accuracy: 0.9718 - val_f1_score: 0.9698 - val_loss: 4.2468 - learning_rate: 6.5610e-04\n",
      "Epoch 535/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9879 - f1_score: 0.9667 - loss: 0.0000e+00 \n",
      "Epoch 535: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9886 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9777 - val_f1_score: 0.9745 - val_loss: 4.6576 - learning_rate: 6.5610e-04\n",
      "Epoch 536/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9885 - f1_score: 0.9831 - loss: 0.0622     \n",
      "Epoch 536: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9885 - f1_score: 0.9847 - loss: 0.0717 - val_accuracy: 0.9781 - val_f1_score: 0.9745 - val_loss: 4.3987 - learning_rate: 6.5610e-04\n",
      "Epoch 537/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9949 - f1_score: 0.9564 - loss: 0.0000e+00 \n",
      "Epoch 537: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9940 - f1_score: 0.9700 - loss: 0.0000e+00 - val_accuracy: 0.9711 - val_f1_score: 0.9745 - val_loss: 3.9903 - learning_rate: 6.5610e-04\n",
      "Epoch 538/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9895 - f1_score: 0.9723 - loss: 7.4152e-06 \n",
      "Epoch 538: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9890 - f1_score: 0.9775 - loss: 2.2516e-05 - val_accuracy: 0.9694 - val_f1_score: 0.9745 - val_loss: 3.9932 - learning_rate: 6.5610e-04\n",
      "Epoch 539/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9913 - f1_score: 0.9640 - loss: 0.0000e+00 \n",
      "Epoch 539: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9911 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9711 - val_f1_score: 0.9745 - val_loss: 4.0254 - learning_rate: 6.5610e-04\n",
      "Epoch 540/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9823 - f1_score: 0.9753 - loss: 0.0047     \n",
      "Epoch 540: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9832 - f1_score: 0.9809 - loss: 0.0055 - val_accuracy: 0.9694 - val_f1_score: 0.9745 - val_loss: 3.5501 - learning_rate: 6.5610e-04\n",
      "Epoch 541/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9909 - f1_score: 0.9640 - loss: 0.0000e+00 \n",
      "Epoch 541: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9900 - f1_score: 0.9769 - loss: 0.0262 - val_accuracy: 0.9697 - val_f1_score: 0.9745 - val_loss: 3.3814 - learning_rate: 6.5610e-04\n",
      "Epoch 542/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9836 - f1_score: 0.9733 - loss: 0.0000e+00 \n",
      "Epoch 542: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9843 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9729 - val_f1_score: 0.9653 - val_loss: 3.9070 - learning_rate: 6.5610e-04\n",
      "Epoch 543/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9805 - f1_score: 0.9640 - loss: 3.7803e-09 \n",
      "Epoch 543: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9832 - f1_score: 0.9775 - loss: 3.6527e-09 - val_accuracy: 0.9732 - val_f1_score: 0.9653 - val_loss: 4.0995 - learning_rate: 6.5610e-04\n",
      "Epoch 544/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9886 - f1_score: 0.9662 - loss: 0.0000e+00 \n",
      "Epoch 544: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9890 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9739 - val_f1_score: 0.9653 - val_loss: 4.1398 - learning_rate: 6.5610e-04\n",
      "Epoch 545/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9911 - f1_score: 0.9760 - loss: 0.0000e+00 \n",
      "Epoch 545: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9907 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9739 - val_f1_score: 0.9653 - val_loss: 4.1495 - learning_rate: 6.5610e-04\n",
      "Epoch 546/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9941 - f1_score: 0.9720 - loss: 0.0000e+00 \n",
      "Epoch 546: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9928 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9739 - val_f1_score: 0.9653 - val_loss: 4.1505 - learning_rate: 6.5610e-04\n",
      "Epoch 547/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9892 - f1_score: 0.9633 - loss: 0.0177    \n",
      "Epoch 547: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9892 - f1_score: 0.9676 - loss: 0.0164 - val_accuracy: 0.9743 - val_f1_score: 0.9698 - val_loss: 3.6785 - learning_rate: 6.5610e-04\n",
      "Epoch 548/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9913 - f1_score: 0.9600 - loss: 2.7844e-05 \n",
      "Epoch 548: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9911 - f1_score: 0.9775 - loss: 3.8877e-05 - val_accuracy: 0.9750 - val_f1_score: 0.9698 - val_loss: 3.6098 - learning_rate: 6.5610e-04\n",
      "Epoch 549/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9885 - f1_score: 0.9709 - loss: 0.0000e+00 \n",
      "Epoch 549: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9896 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5816 - learning_rate: 6.5610e-04\n",
      "Epoch 550/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9939 - f1_score: 0.9564 - loss: 0.0000e+00 \n",
      "Epoch 550: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9935 - f1_score: 0.9700 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5758 - learning_rate: 6.5610e-04\n",
      "Epoch 551/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9931 - f1_score: 0.9754 - loss: 0.0000e+00 \n",
      "Epoch 551: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9926 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5744 - learning_rate: 6.5610e-04\n",
      "Epoch 552/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9898 - f1_score: 0.9600 - loss: 0.0000e+00\n",
      "Epoch 552: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9899 - f1_score: 0.9700 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5742 - learning_rate: 6.5610e-04\n",
      "Epoch 553/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9900 - f1_score: 0.9644 - loss: 0.0000e+00 \n",
      "Epoch 553: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9914 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5742 - learning_rate: 6.5610e-04\n",
      "Epoch 554/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9955 - f1_score: 0.9709 - loss: 0.0000e+00 \n",
      "Epoch 554: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9946 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5741 - learning_rate: 6.5610e-04\n",
      "Epoch 555/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9973 - f1_score: 0.9467 - loss: 0.0000e+00 \n",
      "Epoch 555: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9962 - f1_score: 0.9700 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5741 - learning_rate: 6.5610e-04\n",
      "Epoch 556/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9921 - f1_score: 0.9733 - loss: 3.5352e-08\n",
      "Epoch 556: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9921 - f1_score: 0.9750 - loss: 3.5005e-08 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5741 - learning_rate: 6.5610e-04\n",
      "Epoch 557/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9901 - f1_score: 0.9686 - loss: 0.0000e+00\n",
      "Epoch 557: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9901 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5742 - learning_rate: 6.5610e-04\n",
      "Epoch 558/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9913 - f1_score: 0.9857 - loss: 0.0000e+00\n",
      "Epoch 558: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9914 - f1_score: 0.9875 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5742 - learning_rate: 6.5610e-04\n",
      "Epoch 559/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9931 - f1_score: 0.9733 - loss: 0.0000e+00\n",
      "Epoch 559: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9931 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5742 - learning_rate: 6.5610e-04\n",
      "Epoch 560/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9900 - f1_score: 0.9440 - loss: 8.1631e-10 \n",
      "Epoch 560: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9905 - f1_score: 0.9650 - loss: 7.2520e-10 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5742 - learning_rate: 6.5610e-04\n",
      "Epoch 561/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9971 - f1_score: 0.9840 - loss: 0.0000e+00 \n",
      "Epoch 561: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9960 - f1_score: 0.9900 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5742 - learning_rate: 6.5610e-04\n",
      "Epoch 562/1000\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9974 - f1_score: 0.9760 - loss: 0.0000e+00 \n",
      "Epoch 562: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9965 - f1_score: 0.9850 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5742 - learning_rate: 6.5610e-04\n",
      "Epoch 563/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9909 - f1_score: 0.9893 - loss: 0.0000e+00 \n",
      "Epoch 563: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9910 - f1_score: 0.9900 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5742 - learning_rate: 6.5610e-04\n",
      "Epoch 564/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - f1_score: 0.9750 - loss: 0.0000e+00 \n",
      "Epoch 564: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9933 - f1_score: 0.9875 - loss: 2.8090e-06 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5744 - learning_rate: 6.5610e-04\n",
      "Epoch 565/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9959 - f1_score: 0.9767 - loss: 0.0000e+00\n",
      "Epoch 565: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9952 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5745 - learning_rate: 6.5610e-04\n",
      "Epoch 566/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9953 - f1_score: 0.9636 - loss: 0.0000e+00 \n",
      "Epoch 566: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9944 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5745 - learning_rate: 6.5610e-04\n",
      "Epoch 567/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9946 - f1_score: 0.9667 - loss: 0.0000e+00\n",
      "Epoch 567: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9946 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5744 - learning_rate: 6.5610e-04\n",
      "Epoch 568/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9933 - f1_score: 0.9733 - loss: 0.0000e+00\n",
      "Epoch 568: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9933 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5744 - learning_rate: 6.5610e-04\n",
      "Epoch 569/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9960 - f1_score: 0.9750 - loss: 0.0000e+00 \n",
      "Epoch 569: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9930 - f1_score: 0.9875 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5744 - learning_rate: 6.5610e-04\n",
      "Epoch 570/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9953 - f1_score: 0.9785 - loss: 0.0000e+00\n",
      "Epoch 570: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9946 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5744 - learning_rate: 6.5610e-04\n",
      "Epoch 571/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9947 - f1_score: 0.9633 - loss: 0.0000e+00\n",
      "Epoch 571: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9944 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5744 - learning_rate: 6.5610e-04\n",
      "Epoch 572/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9930 - f1_score: 0.9600 - loss: 0.0000e+00 \n",
      "Epoch 572: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9926 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5744 - learning_rate: 6.5610e-04\n",
      "Epoch 573/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9962 - f1_score: 0.9550 - loss: 0.0000e+00 \n",
      "Epoch 573: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9947 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5744 - learning_rate: 6.5610e-04\n",
      "Epoch 574/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9893 - f1_score: 0.9714 - loss: 0.0000e+00\n",
      "Epoch 574: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9893 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5744 - learning_rate: 6.5610e-04\n",
      "Epoch 575/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9907 - f1_score: 0.9644 - loss: 0.0000e+00 \n",
      "Epoch 575: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9917 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5744 - learning_rate: 6.5610e-04\n",
      "Epoch 576/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9942 - f1_score: 0.9700 - loss: 4.7852e-10\n",
      "Epoch 576: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9937 - f1_score: 0.9775 - loss: 6.2663e-10 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5744 - learning_rate: 6.5610e-04\n",
      "Epoch 577/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9936 - f1_score: 0.9455 - loss: 0.0000e+00\n",
      "Epoch 577: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9932 - f1_score: 0.9625 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5744 - learning_rate: 6.5610e-04\n",
      "Epoch 578/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9940 - f1_score: 0.9745 - loss: 0.0000e+00\n",
      "Epoch 578: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9938 - f1_score: 0.9825 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5744 - learning_rate: 6.5610e-04\n",
      "Epoch 579/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9933 - f1_score: 0.9600 - loss: 0.0000e+00\n",
      "Epoch 579: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9936 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9760 - val_f1_score: 0.9698 - val_loss: 3.5744 - learning_rate: 6.5610e-04\n",
      "Epoch 580/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9910 - f1_score: 0.9686 - loss: 1.4202e-04\n",
      "Epoch 580: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9909 - f1_score: 0.9725 - loss: 1.4584e-04 - val_accuracy: 0.9750 - val_f1_score: 0.9698 - val_loss: 3.5401 - learning_rate: 6.5610e-04\n",
      "Epoch 581/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9943 - f1_score: 0.9771 - loss: 7.1254e-04\n",
      "Epoch 581: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9942 - f1_score: 0.9800 - loss: 6.9772e-04 - val_accuracy: 0.9725 - val_f1_score: 0.9689 - val_loss: 2.7260 - learning_rate: 6.5610e-04\n",
      "Epoch 582/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - f1_score: 0.9743 - loss: 0.0000e+00\n",
      "Epoch 582: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9927 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9715 - val_f1_score: 0.9689 - val_loss: 2.7449 - learning_rate: 6.5610e-04\n",
      "Epoch 583/1000\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9954 - f1_score: 0.9567 - loss: 0.0000e+00\n",
      "Epoch 583: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9955 - f1_score: 0.9675 - loss: 0.0000e+00 - val_accuracy: 0.9718 - val_f1_score: 0.9689 - val_loss: 2.7489 - learning_rate: 6.5610e-04\n",
      "Epoch 584/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9957 - f1_score: 0.9600 - loss: 0.0000e+00 \n",
      "Epoch 584: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9945 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9722 - val_f1_score: 0.9689 - val_loss: 2.7499 - learning_rate: 6.5610e-04\n",
      "Epoch 585/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9941 - f1_score: 0.9745 - loss: 4.0184e-10 \n",
      "Epoch 585: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9940 - f1_score: 0.9825 - loss: 3.6260e-10 - val_accuracy: 0.9722 - val_f1_score: 0.9689 - val_loss: 2.7498 - learning_rate: 6.5610e-04\n",
      "Epoch 586/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9903 - f1_score: 0.9787 - loss: 0.0000e+00\n",
      "Epoch 586: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9903 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9722 - val_f1_score: 0.9689 - val_loss: 2.7498 - learning_rate: 6.5610e-04\n",
      "Epoch 587/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9921 - f1_score: 0.9787 - loss: 0.0000e+00\n",
      "Epoch 587: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9921 - f1_score: 0.9800 - loss: 0.0000e+00 - val_accuracy: 0.9722 - val_f1_score: 0.9689 - val_loss: 2.7498 - learning_rate: 6.5610e-04\n",
      "Epoch 588/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9924 - f1_score: 0.9556 - loss: 0.0000e+00 \n",
      "Epoch 588: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9927 - f1_score: 0.9750 - loss: 5.1139e-07 - val_accuracy: 0.9722 - val_f1_score: 0.9689 - val_loss: 2.7499 - learning_rate: 6.5610e-04\n",
      "Epoch 589/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9943 - f1_score: 0.9743 - loss: 0.0000e+00\n",
      "Epoch 589: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9943 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9725 - val_f1_score: 0.9689 - val_loss: 2.7501 - learning_rate: 6.5610e-04\n",
      "Epoch 590/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9936 - f1_score: 0.9743 - loss: 0.0000e+00 \n",
      "Epoch 590: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9936 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9725 - val_f1_score: 0.9689 - val_loss: 2.7501 - learning_rate: 6.5610e-04\n",
      "Epoch 591/1000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9945 - f1_score: 0.9857 - loss: 0.0000e+00\n",
      "Epoch 591: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9940 - f1_score: 0.9875 - loss: 0.0000e+00 - val_accuracy: 0.9725 - val_f1_score: 0.9689 - val_loss: 2.7501 - learning_rate: 6.5610e-04\n",
      "Epoch 592/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9940 - f1_score: 0.9723 - loss: 1.2636e-04\n",
      "Epoch 592: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9939 - f1_score: 0.9775 - loss: 1.2237e-04 - val_accuracy: 0.9736 - val_f1_score: 0.9689 - val_loss: 2.7363 - learning_rate: 6.5610e-04\n",
      "Epoch 593/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9919 - f1_score: 0.9733 - loss: 0.0000e+00\n",
      "Epoch 593: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9919 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9736 - val_f1_score: 0.9689 - val_loss: 2.7290 - learning_rate: 6.5610e-04\n",
      "Epoch 594/1000\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9948 - f1_score: 0.9692 - loss: 0.0000e+00\n",
      "Epoch 594: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9951 - f1_score: 0.9750 - loss: 0.0000e+00 - val_accuracy: 0.9736 - val_f1_score: 0.9689 - val_loss: 2.7274 - learning_rate: 6.5610e-04\n",
      "Epoch 595/1000\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9954 - f1_score: 0.9600 - loss: 0.0000e+00 \n",
      "Epoch 595: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9947 - f1_score: 0.9775 - loss: 0.0000e+00 - val_accuracy: 0.9736 - val_f1_score: 0.9689 - val_loss: 2.7272 - learning_rate: 6.5610e-04\n",
      "Epoch 596/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9917 - f1_score: 0.9784 - loss: 0.0012    \n",
      "Epoch 596: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9917 - f1_score: 0.9796 - loss: 0.0017 - val_accuracy: 0.9753 - val_f1_score: 0.9689 - val_loss: 2.7618 - learning_rate: 6.5610e-04\n",
      "Epoch 597/1000\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9903 - f1_score: 0.9450 - loss: 0.0000e+00 \n",
      "Epoch 597: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9901 - f1_score: 0.9725 - loss: 0.0000e+00 - val_accuracy: 0.9711 - val_f1_score: 0.9791 - val_loss: 2.8917 - learning_rate: 6.5610e-04\n",
      "Epoch 598/1000\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9928 - f1_score: 0.9660 - loss: 0.0107     \n",
      "Epoch 598: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9930 - f1_score: 0.9759 - loss: 0.0137 - val_accuracy: 0.9753 - val_f1_score: 0.9689 - val_loss: 2.8904 - learning_rate: 6.5610e-04\n",
      "Epoch 599/1000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9917 - f1_score: 0.9627 - loss: 0.0000e+00\n",
      "Epoch 599: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "\n",
      "Epoch 599: saving model to ./model_checkpoints/MultiLayerPerceprtron_articularywordrecognition/checkpoint.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9918 - f1_score: 0.9650 - loss: 0.0000e+00 - val_accuracy: 0.9718 - val_f1_score: 0.9689 - val_loss: 2.8915 - learning_rate: 6.5610e-04\n",
      "Epoch 599: early stopping\n"
     ]
    }
   ],
   "source": [
    "used_dataset = uea_datasets['ArticularyWordRecognition']\n",
    "X, y, metadata = used_dataset\n",
    "\n",
    "get_dummies_object = GetDummiesLabels(\n",
    "    X_raw= X,\n",
    "    y_raw= y,\n",
    "    metadata= metadata\n",
    ")\n",
    "\n",
    "X, y = get_dummies_object.transform()\n",
    "\n",
    "train_test_object = TrainTestSplit(\n",
    "    X_raw= X,\n",
    "    y_raw= y,\n",
    "    metadata= metadata\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_object.transform()\n",
    "\n",
    "model = MultiLayerPerceprtron(\n",
    "    X_train=X_train,\n",
    "    X_test = X_test,\n",
    "    y_train = y_train,\n",
    "    y_test = y_test,\n",
    "    metadata = metadata\n",
    ")\n",
    "\n",
    "model.training_process()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problemname': 'articularywordrecognition',\n",
       " 'timestamps': False,\n",
       " 'missing': False,\n",
       " 'univariate': False,\n",
       " 'equallength': True,\n",
       " 'classlabel': True,\n",
       " 'targetlabel': False,\n",
       " 'class_values': ['1.0',\n",
       "  '2.0',\n",
       "  '3.0',\n",
       "  '4.0',\n",
       "  '5.0',\n",
       "  '6.0',\n",
       "  '7.0',\n",
       "  '8.0',\n",
       "  '9.0',\n",
       "  '10.0',\n",
       "  '11.0',\n",
       "  '12.0',\n",
       "  '13.0',\n",
       "  '14.0',\n",
       "  '15.0',\n",
       "  '16.0',\n",
       "  '17.0',\n",
       "  '18.0',\n",
       "  '19.0',\n",
       "  '20.0',\n",
       "  '21.0',\n",
       "  '22.0',\n",
       "  '23.0',\n",
       "  '24.0',\n",
       "  '25.0']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_flow_masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
